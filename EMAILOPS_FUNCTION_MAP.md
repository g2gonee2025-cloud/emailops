# EmailOps Function Dependency Map & Flow Visualization
**Generated:** 2025-10-15  
**Purpose:** Visual reference for code navigation and understanding system architecture

---

## ğŸ—ºï¸ Complete Module Dependency Graph

```
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚   config.py     â”‚
                           â”‚  (Foundation)   â”‚
                           â”‚                 â”‚
                           â”‚ â€¢ EmailOpsConfigâ”‚
                           â”‚ â€¢ get_config()  â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â†“                 â†“                 â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ exceptions.py  â”‚ â”‚ file_utils.pyâ”‚ â”‚validators.pyâ”‚
         â”‚  (Error Types) â”‚ â”‚  (File I/O)  â”‚ â”‚ (Security)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                â”‚                 â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â†“
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚    llm_runtime.py      â”‚
                      â”‚   (LLM Operations)     â”‚
                      â”‚                        â”‚
                      â”‚ â€¢ complete_text()      â”‚
                      â”‚ â€¢ complete_json()      â”‚
                      â”‚ â€¢ embed_texts()        â”‚
                      â”‚ â€¢ _embed_vertex()      â”‚
                      â”‚ â€¢ Project rotation     â”‚
                      â”‚ â€¢ Rate limiting        â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â†“                        â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ llm_client.py   â”‚      â”‚ processing_     â”‚
            â”‚ (Compat Shim)   â”‚      â”‚ utils.py        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“            â†“            â†“           â†“            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚email_        â”‚ â”‚text_         â”‚ â”‚conversation_ â”‚ â”‚email_        â”‚
â”‚processing.py â”‚ â”‚extraction.py â”‚ â”‚loader.py     â”‚ â”‚indexer.py    â”‚
â”‚              â”‚ â”‚              â”‚ â”‚              â”‚ â”‚              â”‚
â”‚â€¢ clean_email â”‚ â”‚â€¢ extract_textâ”‚ â”‚â€¢ load_       â”‚ â”‚â€¢ build_corpusâ”‚
â”‚  _text()     â”‚ â”‚â€¢ _extract_pdfâ”‚ â”‚  conversationâ”‚ â”‚â€¢ save_index()â”‚
â”‚â€¢ extract_    â”‚ â”‚â€¢ _extract_   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  email_      â”‚ â”‚  docx        â”‚
â”‚  metadata()  â”‚ â”‚â€¢ _extract_   â”‚
â”‚â€¢ split_email â”‚ â”‚  excel       â”‚
â”‚  _thread()   â”‚ â”‚â€¢ _extract_msgâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ text_chunker.py  â”‚
        â”‚                  â”‚
        â”‚â€¢ prepare_index_  â”‚
        â”‚  units()         â”‚
        â”‚â€¢ TextChunker     â”‚
        â”‚â€¢ ChunkConfig     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“            â†“            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚index_    â”‚ â”‚search_   â”‚ â”‚summarize_email_â”‚
â”‚metadata  â”‚ â”‚and_draft â”‚ â”‚thread.py       â”‚
â”‚.py       â”‚ â”‚.py       â”‚ â”‚                â”‚
â”‚          â”‚ â”‚          â”‚ â”‚â€¢ analyze_      â”‚
â”‚â€¢ read_   â”‚ â”‚â€¢ _search â”‚ â”‚  conversation_ â”‚
â”‚  mapping â”‚ â”‚â€¢ draft_  â”‚ â”‚  dir()         â”‚
â”‚â€¢ write_  â”‚ â”‚  email_  â”‚ â”‚â€¢ format_       â”‚
â”‚  mapping â”‚ â”‚  reply_  â”‚ â”‚  analysis_as_  â”‚
â”‚â€¢ validateâ”‚ â”‚  eml()   â”‚ â”‚  markdown()    â”‚
â”‚  _index_ â”‚ â”‚â€¢ draft_  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  compat  â”‚ â”‚  fresh_  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  email_  â”‚
             â”‚  eml()   â”‚
             â”‚â€¢ chat_   â”‚
             â”‚  with_   â”‚
             â”‚  context â”‚
             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“             â†“             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚processor â”‚ â”‚emailops_ â”‚ â”‚parallel_     â”‚
â”‚.py       â”‚ â”‚gui.py    â”‚ â”‚indexer.py    â”‚
â”‚(CLI)     â”‚ â”‚(GUI)     â”‚ â”‚(Multi-worker)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Function Call Flow: Email Indexing

```
USER: Builds Index
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ email_indexer.main()                    â”‚
â”‚   â”œâ”€ _initialize_gcp_credentials()      â”‚
â”‚   â”œâ”€ build_corpus() OR                  â”‚
â”‚   â”‚   build_incremental_corpus()        â”‚
â”‚   â”‚   â”œâ”€ find_conversation_dirs()       â”‚
â”‚   â”‚   â”‚   â””â”€ file_utils.py              â”‚
â”‚   â”‚   â”œâ”€ load_conversation()            â”‚
â”‚   â”‚   â”‚   â””â”€ conversation_loader.py     â”‚
â”‚   â”‚   â”œâ”€ _extract_manifest_metadata()   â”‚
â”‚   â”‚   â””â”€ _build_doc_entries()           â”‚
â”‚   â”‚       â”œâ”€ clean_email_text()         â”‚
â”‚   â”‚       â”‚   â””â”€ email_processing.py    â”‚
â”‚   â”‚       â””â”€ prepare_index_units()      â”‚
â”‚   â”‚           â””â”€ text_chunker.py        â”‚
â”‚   â”œâ”€ embed_texts() [BATCH LOOP]         â”‚
â”‚   â”‚   â””â”€ llm_runtime._embed_vertex()    â”‚
â”‚   â”‚       â”œâ”€ _check_rate_limit()        â”‚
â”‚   â”‚       â”œâ”€ google.genai.Client        â”‚
â”‚   â”‚       â””â”€ _rotate_to_next_project()  â”‚
â”‚   â””â”€ save_index()                       â”‚
â”‚       â”œâ”€ write_mapping()                â”‚
â”‚       â”‚   â””â”€ index_metadata.py          â”‚
â”‚       â”œâ”€ np.save(embeddings.npy)        â”‚
â”‚       â””â”€ faiss.write_index()            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
OUTPUT: FAISS index + mapping.json + embeddings.npy
```

---

## ğŸ” Function Call Flow: Email Search

```
USER: Enters search query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ search_and_draft._search()              â”‚
â”‚   â”œâ”€ validate_index_compatibility()     â”‚
â”‚   â”‚   â””â”€ index_metadata.py              â”‚
â”‚   â”œâ”€ read_mapping()                     â”‚
â”‚   â”‚   â””â”€ index_metadata.py              â”‚
â”‚   â”œâ”€ parse_filter_grammar()             â”‚
â”‚   â”‚   â””â”€ Build SearchFilters object     â”‚
â”‚   â”œâ”€ apply_filters()                    â”‚
â”‚   â”‚   â””â”€ Filter by metadata             â”‚
â”‚   â”œâ”€ embed_texts([query])               â”‚
â”‚   â”‚   â””â”€ _get_cached_query_embedding()  â”‚
â”‚   â”‚       OR _embed_vertex()            â”‚
â”‚   â”œâ”€ Cosine similarity: embs @ query.T  â”‚
â”‚   â”œâ”€ _boost_scores_for_indices()        â”‚
â”‚   â”‚   â””â”€ Recency boost calculation      â”‚
â”‚   â”œâ”€ Summary-aware reranking:           â”‚
â”‚   â”‚   â”œâ”€ _candidate_summary_text()      â”‚
â”‚   â”‚   â”œâ”€ embed_texts([summaries])       â”‚
â”‚   â”‚   â””â”€ _blend_scores()                â”‚
â”‚   â”œâ”€ _mmr_select()                      â”‚
â”‚   â”‚   â””â”€ Diversity optimization         â”‚
â”‚   â”œâ”€ _deduplicate_chunks()              â”‚
â”‚   â”‚   â””â”€ By content_hash                â”‚
â”‚   â””â”€ Read and window text               â”‚
â”‚       â””â”€ _window_text_around_query()    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
OUTPUT: Ranked, deduplicated search results
```

---

## âœ‰ï¸ Function Call Flow: Email Drafting (Reply)

```
USER: Drafts reply to conversation
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ search_and_draft.draft_email_reply_eml()â”‚
â”‚   â”œâ”€ _load_conv_data()                  â”‚
â”‚   â”‚   â”œâ”€ Read Conversation.txt          â”‚
â”‚   â”‚   â”œâ”€ Read manifest.json             â”‚
â”‚   â”‚   â””â”€ _extract_messages_from_        â”‚
â”‚   â”‚       manifest()                    â”‚
â”‚   â”œâ”€ _derive_query_from_last_inbound()  â”‚
â”‚   â”‚   â””â”€ Extract last email content     â”‚
â”‚   â”œâ”€ _gather_context_for_conv()         â”‚
â”‚   â”‚   â””â”€ Same as search flow above      â”‚
â”‚   â”œâ”€ draft_email_structured()           â”‚
â”‚   â”‚   â”œâ”€ PASS 1: Initial Draft          â”‚
â”‚   â”‚   â”‚   â””â”€ complete_json()            â”‚
â”‚   â”‚   â”‚       â””â”€ llm_runtime.py         â”‚
â”‚   â”‚   â”œâ”€ PASS 2: Critic Review          â”‚
â”‚   â”‚   â”‚   â””â”€ complete_json()            â”‚
â”‚   â”‚   â””â”€ PASS 3: Audit Loop (max 5x)    â”‚
â”‚   â”‚       â”œâ”€ _audit_json()              â”‚
â”‚   â”‚       â”‚   â””â”€ complete_json()        â”‚
â”‚   â”‚       â””â”€ complete_text()            â”‚
â”‚   â”‚           [if improvements needed]  â”‚
â”‚   â”œâ”€ _select_attachments_from_citationsâ”‚
â”‚   â”‚   OR _select_attachments_from_      â”‚
â”‚   â”‚      mentions()                     â”‚
â”‚   â”œâ”€ calculate_draft_confidence()       â”‚
â”‚   â”œâ”€ _derive_recipients_for_reply()     â”‚
â”‚   â”œâ”€ _derive_subject_for_reply()        â”‚
â”‚   â””â”€ _build_eml()                       â”‚
â”‚       â””â”€ Create RFC-822 .eml file       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
OUTPUT: .eml file with headers, body, attachments
```

---

## ğŸ’¬ Function Call Flow: Chat

```
USER: Asks question
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ search_and_draft.chat_with_context()    â”‚
â”‚   â”œâ”€ _search()                          â”‚
â”‚   â”‚   â””â”€ Retrieve relevant context      â”‚
â”‚   â”œâ”€ _format_chat_history_for_prompt()  â”‚
â”‚   â”‚   â””â”€ Format previous messages       â”‚
â”‚   â”œâ”€ complete_json()                    â”‚
â”‚   â”‚   â””â”€ Generate answer with schema    â”‚
â”‚   â””â”€ ChatSession.save()                 â”‚
â”‚       â””â”€ Persist history to JSON        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
OUTPUT: Answer with citations & missing info
```

---

## ğŸ“Š Function Call Flow: Thread Analysis

```
USER: Analyzes conversation thread
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ summarize_email_thread.                      â”‚
â”‚   analyze_conversation_dir()                 â”‚
â”‚   â”œâ”€ Read Conversation.txt                   â”‚
â”‚   â”‚   â””â”€ read_text_file()                    â”‚
â”‚   â”œâ”€ clean_email_text()                      â”‚
â”‚   â”œâ”€ analyze_email_thread_with_ledger()      â”‚
â”‚   â”‚   â”œâ”€ PASS 1: Initial Analysis            â”‚
â”‚   â”‚   â”‚   â””â”€ complete_json()                 â”‚
â”‚   â”‚   â”‚       [structured output]            â”‚
â”‚   â”‚   â”œâ”€ _normalize_analysis()               â”‚
â”‚   â”‚   â”‚   â”œâ”€ _coerce_enum()                  â”‚
â”‚   â”‚   â”‚   â”œâ”€ _normalize_subject_line()       â”‚
â”‚   â”‚   â”‚   â””â”€ Schema enforcement              â”‚
â”‚   â”‚   â”œâ”€ PASS 2: Critic Review               â”‚
â”‚   â”‚   â”‚   â””â”€ complete_json()                 â”‚
â”‚   â”‚   â”‚       [check completeness]           â”‚
â”‚   â”‚   â””â”€ PASS 3: Improvement (if needed)     â”‚
â”‚   â”‚       â””â”€ complete_json()                 â”‚
â”‚   â”‚           [enhance analysis]             â”‚
â”‚   â”œâ”€ _merge_manifest_into_analysis()         â”‚
â”‚   â”‚   â”œâ”€ _read_manifest()                    â”‚
â”‚   â”‚   â”œâ”€ _participants_from_manifest()       â”‚
â”‚   â”‚   â””â”€ Union merge of data                 â”‚
â”‚   â””â”€ _normalize_analysis() [final pass]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
OUTPUT: summary.json + summary.md
```

---

## ğŸ—ï¸ Detailed Module Breakdown

### 1. Configuration Layer

#### `config.py` - Central Configuration
```python
EmailOpsConfig
â”œâ”€ load() â†’ classmethod, loads from env
â”œâ”€ get_secrets_dir() â†’ resolve secrets path
â”œâ”€ _is_valid_service_account_json() â†’ validate GCP keys
â”œâ”€ get_credential_file() â†’ find valid credentials
â”œâ”€ update_environment() â†’ sync env vars
â””â”€ to_dict() â†’ export as dict

get_config() â†’ singleton accessor
reset_config() â†’ testing helper
```

**Dependencies:** None (foundation module)  
**Dependent Modules:** ALL (15+)

---

### 2. LLM Runtime Layer

#### `llm_runtime.py` - LLM Operations Hub
```python
# Account Management
VertexAccount â†’ dataclass for GCP accounts
load_validated_accounts() â†’ load & validate accounts
save_validated_accounts() â†’ persist account list
validate_account() â†’ quick validation
_init_vertex() â†’ initialize Vertex AI SDK
reset_vertex_init() â†’ reset init state

# Project Rotation
_ensure_projects_loaded() â†’ lazy load projects
_rotate_to_next_project() â†’ rotate on quota exhaustion

# Rate Limiting
_check_rate_limit() â†’ enforce API limits

# Text Generation
complete_text() â†’ @monitor_performance
    â”œâ”€ _init_vertex()
    â”œâ”€ _vertex_model()
    â”œâ”€ _check_rate_limit()
    â”œâ”€ model.generate_content()
    â””â”€ Retry with rotation on errors

complete_json() â†’ @monitor_performance
    â”œâ”€ Same as complete_text()
    â”œâ”€ response_mime_type: "application/json"
    â””â”€ Fallback to text mode + _extract_json_from_text()

# Embeddings
embed_texts() â†’ @monitor_performance
    â”œâ”€ Provider routing
    â”œâ”€ _embed_vertex() â†’ primary
    â”‚   â”œâ”€ google.genai.Client (preferred)
    â”‚   â””â”€ TextEmbeddingModel (legacy)
    â”œâ”€ _embed_openai()
    â”œâ”€ _embed_azure_openai()
    â”œâ”€ _embed_cohere()
    â”œâ”€ _embed_huggingface()
    â”œâ”€ _embed_qwen()
    â””â”€ _embed_local()

# Utilities
_normalize() â†’ unit normalize vectors
_is_retryable_error() â†’ classify errors
_should_rotate_on() â†’ rotation heuristics
_sleep_with_backoff() â†’ exponential backoff
_extract_json_from_text() â†’ JSON extraction
_find_complete_json_structure() â†’ bracket counting
_is_balanced_json() â†’ validation
_validate_json_syntax() â†’ syntax check
```

**Key Features:**
- Thread-safe rate limiting
- Automatic project rotation on quota exhaustion
- Multi-provider support (7 providers)
- Robust JSON extraction with fallbacks
- Performance monitoring via decorators

---

### 3. Indexing Layer

#### `email_indexer.py` - Vector Index Builder
```python
# Main Entry
main() â†’ CLI entry point
    â”œâ”€ _initialize_gcp_credentials()
    â”œâ”€ Parallel vs Serial decision
    â”œâ”€ build_corpus() OR build_incremental_corpus()
    â””â”€ save_index()

# Corpus Building
build_corpus(root, index_dir, last_run_time?, limit?) 
    â†’ (new_docs, unchanged_docs)
    â”œâ”€ find_conversation_dirs()
    â”œâ”€ load_conversation()
    â”œâ”€ _extract_manifest_metadata()
    â”œâ”€ _build_doc_entries()
    â”‚   â”œâ”€ clean_email_text()
    â”‚   â”œâ”€ prepare_index_units() â†’ chunking
    â”‚   â”œâ”€ _iter_attachment_files()
    â”‚   â””â”€ _att_id() â†’ stable attachment IDs
    â””â”€ Timestamp-based change detection

build_incremental_corpus(root, file_times, mapping, limit?)
    â†’ (new_docs, deleted_ids)
    â”œâ”€ Precise file-level change tracking
    â”œâ”€ Handles deletions correctly
    â””â”€ Per-conversation limit enforcement

# Index Persistence
save_index(index_dir, embeddings, mapping, provider, num_folders)
    â”œâ”€ _atomic_write_bytes(embeddings.npy)
    â”œâ”€ write_mapping(mapping.json)
    â”œâ”€ faiss.write_index(index.faiss) [optional]
    â”œâ”€ save_index_metadata(meta.json)
    â””â”€ check_index_consistency() [post-save]

load_existing_index(index_dir)
    â†’ (faiss_index, mapping, file_times, embeddings)

# Utilities
_atomic_write_bytes() â†’ safe binary write
_atomic_write_text() â†’ safe text write
_prefix_from_id() â†’ normalize doc IDs
_att_id() â†’ generate stable attachment ID
_clean_index_text() â†’ light cleaning for embeddings
_materialize_text_for_docs() â†’ ensure text field
_get_last_run_time() â†’ read timestamp
_save_run_time() â†’ write timestamp
_local_check_index_consistency() â†’ fallback checker
```

**Key Features:**
- Incremental indexing with file-level change tracking
- Atomic writes prevent corruption
- Parallel indexing support (via `parallel_indexer.py`)
- FAISS + NumPy dual storage
- Per-conversation doc limits

---

#### `parallel_indexer.py` - Multi-Worker Indexing
```python
WorkerBatch â†’ dataclass for worker config

parallel_index_conversations(root, index_dir, num_workers, ...)
    â†’ (merged_embeddings, merged_mapping)
    â”œâ”€ Split conversations across workers
    â”œâ”€ Assign GCP accounts round-robin
    â”œâ”€ _index_worker() [in parallel]
    â”‚   â”œâ”€ Set GCP credentials for worker
    â”‚   â”œâ”€ Chunk all assigned conversations
    â”‚   â”œâ”€ Embed all chunks
    â”‚   â””â”€ Save partial results
    â”œâ”€ Merge results (deterministic order)
    â””â”€ Cleanup temp files

_index_worker(batch: WorkerBatch) â†’ worker_result
    [Runs in separate process]
```

**Key Features:**
- Process pool with 'spawn' start method (Windows-safe)
- GCP account per worker (parallel quota)
- Deterministic result merging
- Comprehensive cleanup

---

### 4. Search & Retrieval Layer

#### `search_and_draft.py` - Search, Draft, Chat
```python
# Search Core
_search(ix_dir, query, k, provider, filters?, mmr_lambda?, rerank_alpha?)
    â†’ ranked results
    â”œâ”€ validate_index_compatibility()
    â”œâ”€ parse_filter_grammar() â†’ extract fielded filters
    â”œâ”€ apply_filters() â†’ pre-embedding filter
    â”œâ”€ embed_texts([query]) â†’ with caching
    â”œâ”€ scores = embs @ query.T â†’ cosine similarity
    â”œâ”€ _boost_scores_for_indices() â†’ recency boost
    â”œâ”€ Early deduplication by content_hash
    â”œâ”€ Summary-aware reranking:
    â”‚   â”œâ”€ _candidate_summary_text()
    â”‚   â”œâ”€ embed_texts([summaries])
    â”‚   â””â”€ _blend_scores()
    â”œâ”€ _mmr_select() â†’ diversity via MMR
    â””â”€ _deduplicate_chunks() â†’ final dedup

# Context Gathering
_gather_context_for_conv(ix_dir, conv_id, query, ...)
    â†’ context snippets
    [Same pipeline as _search but filtered to conv_id]

_gather_context_fresh(ix_dir, query, ...)
    â†’ context snippets
    [Same pipeline as _search but no conv_id filter]

# Email Drafting
draft_email_structured(query, sender, context, ...)
    â†’ draft_result
    â”œâ”€ validate_context_quality()
    â”œâ”€ PASS 1: Initial Draft
    â”‚   â””â”€ complete_json() with schema
    â”‚       [citations, missing_info, assumptions]
    â”œâ”€ PASS 2: Critic Review
    â”‚   â””â”€ complete_json() with critic schema
    â”‚       [issues_found, improvements_needed]
    â”œâ”€ PASS 3: Audit Loop (up to 5x)
    â”‚   â”œâ”€ _audit_json() â†’ score on rubric
    â”‚   â””â”€ complete_text() â†’ improve if needed
    â”œâ”€ Attachment Selection:
    â”‚   â”œâ”€ _select_attachments_from_mentions()
    â”‚   â”œâ”€ _select_attachments_from_citations()
    â”‚   â””â”€ select_relevant_attachments() [fallback]
    â””â”€ calculate_draft_confidence()

draft_email_reply_eml(export_root, conv_id, ...)
    â†’ {eml_bytes, draft_json, ...}
    â”œâ”€ _load_conv_data()
    â”œâ”€ _derive_query_from_last_inbound()
    â”œâ”€ _gather_context_for_conv()
    â”œâ”€ draft_email_structured()
    â”œâ”€ _derive_recipients_for_reply()
    â”œâ”€ _derive_subject_for_reply()
    â””â”€ _build_eml()

draft_fresh_email_eml(export_root, to_list, subject, query, ...)
    â†’ {eml_bytes, draft_json, ...}
    â”œâ”€ parse_filter_grammar()
    â”œâ”€ _gather_context_fresh()
    â”œâ”€ draft_email_structured()
    â””â”€ _build_eml()

# EML Construction
_build_eml(from, to, cc, subject, body, attachments?, ...)
    â†’ bytes
    â”œâ”€ Create EmailMessage
    â”œâ”€ Set headers (From, To, Cc, Subject, Date, Message-ID)
    â”œâ”€ Set threading headers (In-Reply-To, References)
    â”œâ”€ Set text/plain body
    â”œâ”€ Add text/html alternative
    â””â”€ Attach files (with size validation)

# Chat
chat_with_context(query, context, chat_history?, temp?)
    â†’ {answer, citations, missing_info}
    â”œâ”€ _format_chat_history_for_prompt()
    â”œâ”€ complete_json() with chat schema
    â””â”€ Fallback to complete_text() + parse

ChatSession â†’ persistent chat
â”œâ”€ load() â†’ from JSON
â”œâ”€ save() â†’ to JSON
â”œâ”€ reset() â†’ clear history
â”œâ”€ add_message(role, content)
â””â”€ recent() â†’ get history

# Filters & Utilities
SearchFilters â†’ dataclass for filters
parse_filter_grammar(query) â†’ (filters, cleaned_query)
    Supports: subject:, from:, to:, cc:, after:, before:, 
              has:attachment, type:pdf, -exclusion

apply_filters(mapping, filters) â†’ filtered indices
validate_context_quality() â†’ check context adequacy
select_relevant_attachments() â†’ heuristic selection
list_conversations_newest_first() â†’ conversation list

# Helper Functions (30+)
_embed_query_compatible() â†’ dimension-safe embedding
_sim_scores_for_indices() â†’ cosine similarity
_boost_scores_for_indices() â†’ recency boost
_mmr_select() â†’ MMR diversity
_blend_scores() â†’ rerank blending
_deduplicate_chunks() â†’ by content_hash
_window_text_around_query() â†’ smart windowing
_bidirectional_expand_text() â†’ expand from center
_sanitize_header_value() â†’ header safety
_clean_addr() â†’ address cleaning
_dedupe_keep_order() â†’ unique preserving order
... and 20 more
```

**Key Features:**
- Three-pass drafting (draft â†’ critic â†’ audit)
- MMR for diversity
- Summary-aware reranking
- Early deduplication before expensive operations
- Query caching (5min TTL)
- Mapping cache with mtime invalidation
- Grammar-based filter parsing
- Attachment selection strategies

---

### 5. Analysis Layer

#### `summarize_email_thread.py` - Thread Analysis
```python
# Main API
analyze_conversation_dir(thread_dir, catalog?, provider?, temp?, merge_manifest?)
    â†’ analysis_dict (async)
    â”œâ”€ read_text_file()
    â”œâ”€ clean_email_text()
    â”œâ”€ analyze_email_thread_with_ledger()
    â””â”€ _merge_manifest_into_analysis()

analyze_email_thread_with_ledger(thread_text, catalog, provider, temp)
    â†’ analysis_dict (async)
    â”œâ”€ PASS 1: Initial Analysis
    â”‚   â”œâ”€ complete_json() with full schema
    â”‚   â”œâ”€ _try_load_json() â†’ robust parsing
    â”‚   â””â”€ _normalize_analysis()
    â”œâ”€ PASS 2: Critic Review
    â”‚   â”œâ”€ complete_json() with critic schema
    â”‚   â””â”€ Check completeness_score
    â””â”€ PASS 3: Improvement Loop (if score < 85)
        â”œâ”€ complete_json() with improvement prompt
        â”œâ”€ _normalize_analysis()
        â””â”€ _union_analyses() â†’ merge without data loss

format_analysis_as_markdown(analysis) â†’ markdown_str
    [Formats all sections: summary, participants, facts ledger, etc.]

# JSON Parsing (Robust)
_try_load_json(data) â†’ dict
    â”œâ”€ Strategy 1: Direct json.loads()
    â”œâ”€ Strategy 2: Extract from ```json fence
    â””â”€ Strategy 3: _extract_first_balanced_json_object()

_extract_first_balanced_json_object(s) â†’ json_str?
    [Bracket counting with string literal handling]

# Normalization & Validation
_normalize_analysis(data, catalog) â†’ dict
    â”œâ”€ Schema enforcement
    â”œâ”€ _coerce_enum() â†’ standardize enums
    â”œâ”€ _normalize_subject_line() â†’ clean subject
    â”œâ”€ _normalize_name() â†’ clean names
    â”œâ”€ Apply size caps (MAX_PARTICIPANTS, etc.)
    â””â”€ De-duplication

_coerce_enum(val, allowed, default, synonyms?) â†’ str
    [Map variants to canonical values]

# Manifest Integration
_read_manifest(convo_dir) â†’ manifest_dict
    [BOM-tolerant, control char stripping]

_participants_from_manifest(manifest) â†’ participant_list
    [Extract from first message]

_merge_manifest_into_analysis(analysis, convo_dir, raw_text)
    â†’ enriched_analysis
    â”œâ”€ Union merge participants
    â”œâ”€ Add start/end dates
    â””â”€ Preserve existing data

_union_analyses(improved, initial, catalog) â†’ merged_dict
    [Union merge to prevent data loss]

# File Operations
_atomic_write_text(path, content) â†’ None
    [Temp file + os.replace with retries]

_append_todos_csv(root, thread_name, todos) â†’ None
    â”œâ”€ De-duplication by (owner, action, thread)
    â””â”€ DictWriter for safety

# Utilities
_safe_str(v, max_len) â†’ str
_md_escape(v) â†’ str [markdown escaping]
_normalize_name(n) â†’ str
_normalize_subject_line(s) â†’ str
_safe_csv_cell(x) â†’ str [injection prevention]
_calc_max_output_tokens() â†’ int [dynamic budget]
_llm_routing_kwargs(provider) â†’ dict
_retry(callable, retries?, delay?) â†’ result (async helper)
```

**Schema:** 8-field facts ledger (known_facts, key_dates, commitments, etc.)  
**Workflow:** 3-pass analysis with union merging

---

### 6. Utility Modules

#### `text_chunker.py` - Text Splitting
```python
ChunkConfig â†’ dataclass (chunk_size, overlap, etc.)

TextChunker(config)
â””â”€ chunk_text(text, metadata?) â†’ chunk_list

prepare_index_units(text, doc_id, doc_path, ...)
    â†’ chunk_list [for indexing]
    â”œâ”€ _apply_progressive_scaling() â†’ adaptive sizing
    â”œâ”€ _ranges_with_overlap()
    â”‚   â”œâ”€ _compute_breakpoints() â†’ sentence/para boundaries
    â”‚   â””â”€ Forward progress guarantee
    â””â”€ Generate chunk IDs: doc_id, doc_id::chunk1, ...

# Internal
_apply_progressive_scaling() â†’ (size, overlap)
    [Scale up for large docs]

_compute_breakpoints(text, respect_sentences?, respect_paragraphs?)
    â†’ breakpoint_list
    [PARA_RE, SENT_RE patterns]

_ranges_with_overlap(text, size, overlap, ...)
    â†’ [(start, end), ...]
    [Boundary-aware splitting]
```

**Key Features:**
- Boundary-aware (sentence, paragraph)
- Progressive scaling for large docs
- Guaranteed forward progress
- Tiny tail merging

---

#### `text_extraction.py` - File Format Handling
```python
extract_text(path, max_chars?, use_cache?) â†’ str
    â”œâ”€ Cache check (1-hour TTL)
    â”œâ”€ Format routing:
    â”‚   â”œâ”€ TEXT: read_text_file()
    â”‚   â”œâ”€ PDF: _extract_pdf()
    â”‚   â”œâ”€ DOCX: _extract_word_document()
    â”‚   â”œâ”€ DOC: _extract_text_from_doc_win32() [Windows]
    â”‚   â”œâ”€ XLSX: _extract_excel()
    â”‚