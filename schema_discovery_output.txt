2025-12-24 11:21:42,669 - INFO - Fetching 100 largest conversations...
2025-12-24 11:21:43,433 - INFO - Custom GPU scaler disabled - using DO native autoscaler
2025-12-24 11:21:43,433 - INFO - Starting graph extraction on 20 texts with ThreadPool...
2025-12-24 11:21:43,445 - INFO - Extracting graph from 1202 chars (Chunks: 1)
2025-12-24 11:21:43,477 - INFO - Extracting graph from 1822 chars (Chunks: 1)
2025-12-24 11:21:55,956 - INFO - Initializing OpenAI client for LLM Model 'openai-gpt-oss-120b' at https://inference.do-ai.run/v1
2025-12-24 11:22:10,574 - INFO - HTTP Request: POST https://inference.do-ai.run/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-24 11:22:12,481 - INFO - Extracting graph from 2076 chars (Chunks: 1)
2025-12-24 11:22:18,831 - INFO - HTTP Request: POST https://inference.do-ai.run/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-24 11:22:18,873 - INFO - Extracting graph from 4038 chars (Chunks: 1)
2025-12-24 11:22:23,561 - INFO - HTTP Request: POST https://inference.do-ai.run/v1/chat/completions "HTTP/1.1 200 OK"
2025-12-24 11:22:23,605 - INFO - Extracting graph from 454 chars (Chunks: 1)
