diff --git a/scripts/per_issue_fixer.py b/cli/src/cortex_cli/cmd_fix.py
similarity index 70%
rename from scripts/per_issue_fixer.py
rename to cli/src/cortex_cli/cmd_fix.py
index 8a0578dc..e70815d8 100644
--- a/scripts/per_issue_fixer.py
+++ b/cli/src/cortex_cli/cmd_fix.py
@@ -6,13 +6,14 @@
 Each patch fixes exactly ONE issue, making them simpler and more reliable.
 Uses the same patterns as bulk_code_review.py.
 """
-
+import argparse
 import json
 import logging
 import os
 import sys
 from concurrent.futures import ThreadPoolExecutor, as_completed
 from pathlib import Path
+from typing import Any, Dict, List
 
 import requests
 from dotenv import load_dotenv
@@ -27,25 +28,94 @@
 logger = logging.getLogger("per_issue_fixer")
 
 # --- Configuration ---
-PROJECT_ROOT = Path(__file__).parent.parent.resolve()
+PROJECT_ROOT = Path(__file__).parent.parent.parent.parent.resolve()
 PATCHES_DIR = PROJECT_ROOT / "patches_per_issue"
-PATCHES_DIR.mkdir(exist_ok=True)
 
-# Concurrency control
-MAX_WORKERS = 10
 
-# Model
-MODEL = "openai-gpt-5"
+def setup_fix_parser(subparsers: Any):
+    """Setup the 'fix-issues' command parser."""
+    fix_parser = subparsers.add_parser(
+        "fix-issues",
+        help="Generate patches for issues in bulk_review_report_v2.json",
+        description="""
+Generates one micro-patch per individual error from bulk_review_report_v2.json.
+Each patch fixes exactly ONE issue, making them simpler and more reliable.
+        """,
+        formatter_class=argparse.RawDescriptionHelpFormatter,
+    )
+    fix_parser.add_argument(
+        "--model",
+        default=os.getenv("FIXER_MODEL", "gpt-4"),
+        help="The model to use for generating patches (default: gpt-4, or FIXER_MODEL env var)",
+    )
+    fix_parser.add_argument(
+        "--max-workers",
+        type=int,
+        default=10,
+        help="Maximum number of concurrent workers (default: 10)",
+    )
+    fix_parser.set_defaults(
+        func=lambda args: run_fixer(model=args.model, max_workers=args.max_workers)
+    )
+
+def run_fixer(model: str, max_workers: int):
+    """
+    Main function to generate patches for issues.
+    """
+    PATCHES_DIR.mkdir(exist_ok=True)
+
+    # API Configuration (same as bulk_code_review.py)
+    API_KEY = os.getenv("LLM_API_KEY") or os.getenv("DO_API_KEY")
+    BASE_URL = (os.getenv("LLM_ENDPOINT") or "https://inference.do-ai.run/v1").rstrip("/")
 
-# API Configuration (same as bulk_code_review.py)
-API_KEY = os.getenv("LLM_API_KEY") or os.getenv("DO_API_KEY")
-BASE_URL = (os.getenv("LLM_ENDPOINT") or "https://inference.do-ai.run/v1").rstrip("/")
+    if not API_KEY:
+        print("Missing API key. Set LLM_API_KEY or DO_API_KEY.")
+        sys.exit(1)
+
+    HEADERS = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
 
-if not API_KEY:
-    print("Missing API key. Set LLM_API_KEY or DO_API_KEY.")
-    sys.exit(1)
+    logger.info("Loading issues from bulk_review_report_v2.json...")
+    issues = load_report()
+    logger.info(f"Found {len(issues)} issues to process")
+    logger.info(f"Model: {model}")
+    logger.info(f"Workers: {max_workers}")
+    logger.info(f"Output: {PATCHES_DIR}\n")
+
+    results = []
+    success_count = 0
+    failed_count = 0
+
+    with ThreadPoolExecutor(max_workers=max_workers) as executor:
+        future_to_idx = {
+            executor.submit(process_issue, issue, i, model, BASE_URL, HEADERS): i
+            for i, issue in enumerate(issues)
+        }
 
-HEADERS = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
+        for future in as_completed(future_to_idx):
+            idx = future_to_idx[future]
+            try:
+                result = future.result()
+                results.append(result)
+
+                if result["status"] == "success":
+                    success_count += 1
+                    if success_count % 50 == 0:
+                        logger.info(f"Progress: {success_count} patches generated...")
+                else:
+                    failed_count += 1
+            except Exception as e:
+                failed_count += 1
+                logger.error(f"Exception for issue {idx}: {e}")
+
+    # Summary
+    print("\n" + "=" * 60)
+    print("PER-ISSUE PATCH GENERATION COMPLETE")
+    print("=" * 60)
+    print(f"Total Issues: {len(issues)}")
+    print(f"Patches Generated: {success_count}")
+    print(f"Failed: {failed_count}")
+    print(f"Output Directory: {PATCHES_DIR}")
+    print("=" * 60)
 
 # Prompt for fixing a single issue
 FIX_PROMPT = """
@@ -64,7 +134,7 @@
 <output_format>
 --- {file_path}
 +++ {file_path}
-@@ -{hunk_start},{hunk_old} +{hunk_start},{hunk_new} @@
+@@ -{hunk_start},{hunk_old} @@
  context line (space prefix)
 -removed line (minus prefix)
 +added line (plus prefix)
@@ -97,7 +167,8 @@ def get_code_context(
     try:
         with open(full_path, encoding="utf-8") as f:
             lines = f.readlines()
-    except Exception:
+    except (IOError, OSError) as e:
+        logger.error(f"Error reading file {full_path}: {e}")
         return "", 0, 0
 
     start = max(0, line - context - 1)
@@ -111,17 +182,17 @@ def get_code_context(
     return "\n".join(numbered), start + 1, end
 
 
-def call_llm(prompt: str) -> str:
+def call_llm(prompt: str, model: str, base_url: str, headers: Dict[str, str]) -> str:
     """Make a single LLM API call (same pattern as bulk_code_review.py)."""
-    url = f"{BASE_URL}/chat/completions"
+    url = f"{base_url}/chat/completions"
     payload = {
-        "model": MODEL,
+        "model": model,
         "messages": [{"role": "user", "content": prompt}],
         "temperature": 0.0,
         "max_tokens": 1000,
     }
     try:
-        resp = requests.post(url, json=payload, headers=HEADERS, timeout=60)
+        resp = requests.post(url, json=payload, headers=headers, timeout=60)
         if resp.status_code == 200:
             data = resp.json()
             content = (
@@ -141,7 +212,7 @@ def call_llm(prompt: str) -> str:
         return ""
 
 
-def process_issue(issue: dict, idx: int) -> dict:
+def process_issue(issue: dict, idx: int, model: str, base_url: str, headers: Dict[str, str]) -> dict:
     """Generate a patch for a single issue."""
     file_path = issue.get("file", "")
     line = issue.get("line") or 1
@@ -167,10 +238,9 @@ def process_issue(issue: dict, idx: int) -> dict:
         code_context=code_context,
         hunk_start=start_line,
         hunk_old=end_line - start_line + 1,
-        hunk_new=end_line - start_line + 1,
     )
 
-    patch = call_llm(prompt)
+    patch = call_llm(prompt, model, base_url, headers)
     if not patch:
         result["status"] = "llm_failed"
         return result
@@ -186,52 +256,3 @@ def process_issue(issue: dict, idx: int) -> dict:
     result["status"] = "success"
     result["patch"] = str(patch_path)
     return result
-
-
-def main():
-    logger.info("Loading issues from bulk_review_report_v2.json...")
-    issues = load_report()
-    logger.info(f"Found {len(issues)} issues to process")
-    logger.info(f"Model: {MODEL}")
-    logger.info(f"Workers: {MAX_WORKERS}")
-    logger.info(f"Output: {PATCHES_DIR}\n")
-
-    results = []
-    success_count = 0
-    failed_count = 0
-
-    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
-        future_to_idx = {
-            executor.submit(process_issue, issue, i): i
-            for i, issue in enumerate(issues)
-        }
-
-        for future in as_completed(future_to_idx):
-            idx = future_to_idx[future]
-            try:
-                result = future.result()
-                results.append(result)
-
-                if result["status"] == "success":
-                    success_count += 1
-                    if success_count % 50 == 0:
-                        logger.info(f"Progress: {success_count} patches generated...")
-                else:
-                    failed_count += 1
-            except Exception as e:
-                failed_count += 1
-                logger.error(f"Exception for issue {idx}: {e}")
-
-    # Summary
-    print("\n" + "=" * 60)
-    print("PER-ISSUE PATCH GENERATION COMPLETE")
-    print("=" * 60)
-    print(f"Total Issues: {len(issues)}")
-    print(f"Patches Generated: {success_count}")
-    print(f"Failed: {failed_count}")
-    print(f"Output Directory: {PATCHES_DIR}")
-    print("=" * 60)
-
-
-if __name__ == "__main__":
-    main()
diff --git a/cli/src/cortex_cli/main.py b/cli/src/cortex_cli/main.py
index e0d85de3..f99288b9 100644
--- a/cli/src/cortex_cli/main.py
+++ b/cli/src/cortex_cli/main.py
@@ -148,6 +148,7 @@ def model_dump(self) -> dict[str, Any]: ...
     ("embeddings", "Embedding management (stats, backfill)"),
     ("s3", "S3/Spaces storage (list, ingest)"),
     ("maintenance", "System maintenance (resolve-entities)"),
+    ("fix-issues", "Generate patches for SonarQube issues"),
 ]
 
 COMMON_OPTIONS = [
@@ -1320,11 +1321,13 @@ def main(args: list[str] | None = None) -> None:
     from cortex_cli.cmd_embeddings import setup_embeddings_parser
     from cortex_cli.cmd_maintenance import setup_maintenance_parser
     from cortex_cli.cmd_s3 import setup_s3_parser
+    from cortex_cli.cmd_fix import setup_fix_parser
 
     setup_db_parser(subparsers)
     setup_embeddings_parser(subparsers)
     setup_s3_parser(subparsers)
     setup_maintenance_parser(subparsers)
+    setup_fix_parser(subparsers)
 
     # Parse arguments
     parsed_args = parser.parse_args(args)
diff --git a/cli/tests/test_cmd_fix.py b/cli/tests/test_cmd_fix.py
new file mode 100644
index 00000000..2dfefa15
--- /dev/null
+++ b/cli/tests/test_cmd_fix.py
@@ -0,0 +1,24 @@
+import argparse
+from unittest.mock import patch
+
+from cortex_cli.cmd_fix import run_fixer, setup_fix_parser
+
+
+def test_setup_fix_parser():
+    """Test that the 'fix-issues' command is registered correctly."""
+    parser = argparse.ArgumentParser()
+    subparsers = parser.add_subparsers()
+    setup_fix_parser(subparsers)
+    args = parser.parse_args(["fix-issues"])
+    assert hasattr(args, "func")
+
+
+@patch("cortex_cli.cmd_fix.run_fixer")
+def test_fix_issues_command(mock_run_fixer):
+    """Test that the 'fix-issues' command calls the correct function."""
+    parser = argparse.ArgumentParser()
+    subparsers = parser.add_subparsers()
+    setup_fix_parser(subparsers)
+    args = parser.parse_args(["fix-issues", "--model", "test-model", "--max-workers", "5"])
+    args.func(args)
+    mock_run_fixer.assert_called_once_with(model="test-model", max_workers=5)
