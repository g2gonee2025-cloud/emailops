# Embedding Provider (choose one)
EMBED_PROVIDER=vertex           # Options: vertex, openai, azure, cohere, huggingface, local

# ----- GCP / Vertex -----
export GCP_PROJECT="<YOUR_PROJECT_ID>"
export GCP_REGION="global"                  # use Vertex global endpoint
export EMBED_PROVIDER="vertex"
export VERTEX_EMBED_MODEL="gemini-embedding-001"

# Optional: shrink vectors to save index size (tradeoff: a bit of quality)
# export VERTEX_EMBED_DIM="1536"            # or 768; default is 3072

# For the Gen AI SDK to talk to Vertex without extra args:
export GOOGLE_CLOUD_PROJECT="$GCP_PROJECT"
export GOOGLE_CLOUD_LOCATION="$GCP_REGION"
export GOOGLE_GENAI_USE_VERTEXAI="True"

# OpenAI Configuration (for openai provider)
# OPENAI_API_KEY=your-openai-key

# Local Model Configuration (for local provider)
# LOCAL_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Index Configuration
INDEX_DIRNAME=_index
EMBED_BATCH=128
HALF_LIFE_DAYS=30

# Logging
LOG_LEVEL=INFO
