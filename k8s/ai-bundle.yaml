apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-bundle
  namespace: emailops
  labels:
    app: emailops
    component: ai-bundle
spec:
  replicas: 1
  selector:
    matchLabels:
      app: emailops
      component: ai-bundle
  template:
    metadata:
      labels:
        app: emailops
        component: ai-bundle
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8000"
    spec:
      priorityClassName: emailops-high-priority
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
      containers:
        - name: vllm-bundle
          image: vllm/vllm-openai:latest
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "Starting Embeddings Model Only (Port 8000)..."
              python3 -m vllm.entrypoints.openai.api_server \
                --model tencent/KaLM-Embedding-Gemma3-12B-2511 \
                --port 8000 \
                --max-model-len 8192 \
                --enforce-eager \
                --trust-remote-code \
                --max-num-seqs 256 \
                --gpu-memory-utilization 0.85

          env:
            - name: HF_HUB_ENABLE_HF_TRANSFER
              value: "1"
          ports:
            - containerPort: 8000
              name: embeddings
            - containerPort: 8001
              name: reranker
          volumeMounts:
            - mountPath: /dev/shm
              name: dshm
          resources:
            requests:
              memory: "48Gi"
              cpu: "6"
              nvidia.com/gpu: "1"
            limits:
              memory: "64Gi"
              cpu: "10"
              nvidia.com/gpu: "1"
          startupProbe:
            httpGet:
              path: /health
              port: 8000
            failureThreshold: 120
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 120
            periodSeconds: 30
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      nodeSelector:
        doks.digitalocean.com/node-pool: pool-gpu-l40s
---
apiVersion: v1
kind: Service
metadata:
  name: embeddings-api
  namespace: emailops
  labels:
    app: emailops
    component: embeddings
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 8000
      protocol: TCP
      name: http
  selector:
    app: emailops
    component: ai-bundle
---
apiVersion: v1
kind: Service
metadata:
  name: reranker-api
  namespace: emailops
  labels:
    app: emailops
    component: reranker
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 8001
      protocol: TCP
      name: http
  selector:
    app: emailops
    component: ai-bundle
