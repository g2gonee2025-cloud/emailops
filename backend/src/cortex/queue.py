"""\nQueue abstraction for Cortex.\n\nImplements ยง7.4 of the Canonical Blueprint.\nAbstracts the underlying queue mechanism (Redis Streams, Celery, etc.)\nas per Blueprint ยง2.1.\n"""\n\nfrom __future__ import annotations\n\nimport json\nimport logging\nimport os\nimport socket\nimport threading\nimport time\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom typing import Any, Optional\n\nlogger = logging.getLogger(__name__)\n\n\n# -----------------------------------------------------------------------------\n# Job Status and Data Classes\n# -----------------------------------------------------------------------------\n\n\nclass JobStatus:\n    """Represents the status of a job."""\n\n    PENDING = "pending"\n    PROCESSING = "processing"\n    COMPLETED = "completed"\n    FAILED = "failed"\n    DEAD_LETTER = "dead_letter"\n\n\n@dataclass\nclass Job:\n    """Represents a job in the queue."""\n\n    id: str\n    type: str\n    payload: dict[str, Any]\n    priority: int = 0\n    status: str = JobStatus.PENDING\n    attempts: int = 0\n    max_attempts: int = 3\n    created_at: float = field(default_factory=time.time)\n    started_at: float | None = None\n    completed_at: float | None = None\n    error: str | None = None\n\n    def to_dict(self) -> dict[str, Any]:\n        """Convert job to dictionary."""\n        return {\n            "id": self.id,\n            "type": self.type,\n            "payload": self.payload,\n            "priority": self.priority,\n            "status": self.status,\n            "attempts": self.attempts,\n            "max_attempts": self.max_attempts,\n            "created_at": self.created_at,\n            "started_at": self.started_at,\n            "completed_at": self.completed_at,\n            "error": self.error,\n        }\n\n    @classmethod\n    def from_dict(cls, data: dict[str, Any]) -> Job:\n        """Create job from dictionary."""\n        return cls(\n            id=data["id"],\n            type=data["type"],\n            payload=data.get("payload", {}),\n            priority=data.get("priority", 0),\n            status=data.get("status", JobStatus.PENDING),\n            attempts=data.get("attempts", 0),\n            max_attempts=data.get("max_attempts", 3),\n            created_at=data.get("created_at", time.time()),\n            started_at=data.get("started_at"),\n            completed_at=data.get("completed_at"),\n            error=data.get("error"),\n        )\n\n\n# -----------------------------------------------------------------------------\n# Abstract Base Class\n# -----------------------------------------------------------------------------\n\n\nclass JobQueue(ABC):\n    """Abstract base class for job queues."""\n\n    @abstractmethod\n    def enqueue(self, job_type: str, payload: dict[str, Any], priority: int = 0) -> str:\n        """\n        Enqueue a job.\n\n        Args:\n            job_type: Type of job (e.g., 'ingest', 'reindex')\n            payload: Job payload data\n            priority: Job priority (higher = more urgent)\n\n        Returns:\n            Job ID\n        """\n        pass\n\n    @abstractmethod\n    def dequeue(self, job_types: list[str], timeout: int = 10) -> dict[str, Any] | None:\n        """\n        Dequeue a job.\n\n        Args:\n            job_types: List of job types to accept\n            timeout: Maximum time to wait in seconds\n\n        Returns:\n            Job dictionary or None if no job available\n        """\n        pass\n\n    @abstractmethod\n    def ack(self, job_id: str) -> None:\n        """\n        Acknowledge job completion.\n\n        Args:\n            job_id: ID of the completed job\n        """\n        pass\n\n    @abstractmethod\n    def nack(self, job_id: str, error: str | None = None) -> None:\n        """\n        Negative acknowledge (fail/retry).\n\n        Args:\n            job_id: ID of the failed job\n            error: Optional error message\n        """\n        pass\n\n    @abstractmethod\n    def get_job_status(self, job_id: str) -> dict[str, Any] | None:\n        """\n        Get job status.\n\n        Args:\n            job_id: ID of the job\n\n        Returns:\n            Job status dictionary or None\n        """\n        pass\n\n    @abstractmethod\n    def get_queue_stats(self) -> dict[str, int]:\n        """\n        Get queue statistics.\n\n        Returns:\n            Dictionary with queue stats (pending, processing, etc.)\n        """\n        pass\n\n\n# -----------------------------------------------------------------------------\n# In-Memory Queue (Testing Only)\n# -----------------------------------------------------------------------------\n\n\nclass InMemoryQueue(JobQueue):\n    """Simple in-memory queue for testing purposes only."""\n\n    def __init__(self):\n        from queue import PriorityQueue\n\n        self._queue = PriorityQueue()\n        self._jobs: dict[str, Job] = {}\n        self._lock = threading.Lock()\n\n    def enqueue(self, job_type: str, payload: dict[str, Any], priority: int = 0) -> str:\n        job_id = str(uuid.uuid4())\n        job = Job(\n            id=job_id,\n            type=job_type,\n            payload=payload,\n            priority=priority,\n        )\n        with self._lock:\n            self._jobs[job_id] = job\n            # PriorityQueue is min-heap, so negate priority for higher = more urgent\n            self._queue.put((-priority, job.created_at, job_id))\n        logger.debug(f"Enqueued job {job_id} of type {job_type}")\n        return job_id\n\n    def dequeue(self, job_types: list[str], timeout: int = 10) -> dict[str, Any] | None:\n        from queue import Empty\n\n        start = time.time()\n        while time.time() - start < timeout:\n            try:\n                with self._lock:\n                    _, _, job_id = self._queue.get_nowait()\n                    job = self._jobs.get(job_id)\n                    if job and job.type in job_types:\n                        job.status = JobStatus.PROCESSING\n                        job.started_at = time.time()\n                        job.attempts += 1\n                        return job.to_dict()\n                    elif job:\n                        # Put back if not matching type\n                        self._queue.put((-job.priority, job.created_at, job_id))\n                        time.sleep(\n                            0.1\n                        )  # Prevent tight loop processing only non-matching jobs\n            except Empty:\n                # Avoid busy-waiting if the queue is empty\n                time.sleep(0.1)\n        return None\n\n    def ack(self, job_id: str) -> None:\n        with self._lock:\n            if job_id in self._jobs:\n                job = self._jobs[job_id]\n                job.status = JobStatus.COMPLETED\n                job.completed_at = time.time()\n                logger.debug(f"Acknowledged job {job_id}")\n\n    def nack(self, job_id: str, error: str | None = None) -> None:\n        with self._lock:\n            if job_id in self._jobs:\n                job = self._jobs[job_id]\n                job.error = error\n                if job.attempts >= job.max_attempts:\n                    job.status = JobStatus.DEAD_LETTER\n                    logger.warning(\n                        f"Job {job_id} moved to dead letter after {job.attempts} attempts"\n                    )\n                else:\n                    job.status = JobStatus.PENDING\n                    self._queue.put((-job.priority, job.created_at, job_id))\n                    logger.debug(f"Job {job_id} requeued (attempt {job.attempts})")\n\n    def get_job_status(self, job_id: str) -> dict[str, Any] | None:\n        with self._lock:\n            job = self._jobs.get(job_id)\n            return job.to_dict() if job else None\n\n    def get_queue_stats(self) -> dict[str, int]:\n        with self._lock:\n            stats = {\n                "pending": 0,\n                "processing": 0,\n                "completed": 0,\n                "failed": 0,\n                "dead_letter": 0,\n            }\n            for job in self._jobs.values():\n                if job.status == JobStatus.PENDING:\n                    stats["pending"] += 1\n                elif job.status == JobStatus.PROCESSING:\n                    stats["processing"] += 1\n                elif job.status == JobStatus.COMPLETED:\n                    stats["completed"] += 1\n                elif job.status == JobStatus.FAILED:\n                    stats["failed"] += 1\n                elif job.status == JobStatus.DEAD_LETTER:\n                    stats["dead_letter"] += 1\n            return stats\n\n\n# -----------------------------------------------------------------------------\n# Redis Streams Queue (Production)\n# -----------------------------------------------------------------------------\n\n\nclass RedisStreamsQueue(JobQueue):\n    """\n    Redis Streams-based job queue for production use.\n\n    Implements Blueprint ยง7.4:\n    * Reliable message delivery with consumer groups\n    * Automatic dead-letter handling\n    * Job status tracking\n    * Priority support via multiple streams\n    """\n\n    # Stream/key naming\n    STREAM_PREFIX = "cortex:jobs:"\n    STATUS_PREFIX = "cortex:job_status:"\n    CONSUMER_GROUP = "cortex_workers"\n    DEAD_LETTER_STREAM = "cortex:dead_letter"\n\n    def __init__(\n        self,\n        redis_url: str = "redis://localhost:6379",\n        job_types: list[str] | None = None,\n        max_retries: int = 3,\n        visibility_timeout: int = 300,  # 5 minutes\n        block_timeout: int = 5000,  # 5 seconds in ms\n    ):\n        """\n        Initialize Redis Streams queue.\n\n        Args:\n            redis_url: Redis connection URL\n            max_retries: Maximum retry attempts before dead-letter\n            visibility_timeout: Seconds before unacked job is reclaimed\n            block_timeout: Milliseconds to block waiting for jobs\n            job_types: List of all known job types (optional)\n        """\n        try:\n            import redis\n        except ImportError:\n            raise ImportError(\n                "redis package required for RedisStreamsQueue. "\n                "Install with: pip install redis"\n            )\n\n        self._redis = redis.from_url(redis_url, decode_responses=True)\n        self._max_retries = max_retries\n        self._visibility_timeout = visibility_timeout\n        self._block_timeout = block_timeout\n        self._consumer_name = f"{socket.gethostname()}-{os.getpid()}"\n        self._lock = threading.Lock()\n        self._job_types = job_types or []\n\n        # Initialize consumer groups for known job types\n        if self._job_types:\n            self._ensure_consumer_groups(self._job_types)\n\n        logger.info(\n            f"RedisStreamsQueue initialized with consumer: {self._consumer_name}"\n        )\n\n    def _stream_name(self, job_type: str, priority: int = 0) -> str:\n        """Get stream name for job type and priority."""\n        if priority > 5:\n            return f"{self.STREAM_PREFIX}{job_type}:high"\n        elif priority < -5:\n            return f"{self.STREAM_PREFIX}{job_type}:low"\n        return f"{self.STREAM_PREFIX}{job_type}:normal"\n\n    def _ensure_consumer_groups(self, job_types: list[str]) -> None:\n        """Ensure consumer groups exist for all job types and priorities."""\n        priorities = ["high", "normal", "low"]\n        for job_type in job_types:\n            for priority in priorities:\n                stream = f"{self.STREAM_PREFIX}{job_type}:{priority}"\n                try:\n                    self._redis.xgroup_create(\n                        stream, self.CONSUMER_GROUP, id="0", mkstream=True\n                    )\n                    logger.debug(f"Created consumer group for stream: {stream}")\n                except Exception as e:\n                    # Ignore BUSYGROUP errors (group already exists)\n                    if "BUSYGROUP" in str(e):\n                        continue\n                    logger.warning(f"Failed to create consumer group for {stream}: {e}")\n\n    def enqueue(self, job_type: str, payload: dict[str, Any], priority: int = 0) -> str:\n        """Enqueue a job to Redis Streams."""\n        job_id = str(uuid.uuid4())\n        job = Job(\n            id=job_id,\n            type=job_type,\n            payload=payload,\n            priority=priority,\n        )\n\n        stream = self._stream_name(job_type, priority)\n\n        # Store job data\n        job_data = {\n            "id": job_id,\n            "type": job_type,\n            "payload": json.dumps(payload),\n            "priority": str(priority),\n            "created_at": str(job.created_at),\n            "max_attempts": str(job.max_attempts),\n        }\n\n        # Add to stream\n        self._redis.xadd(stream, job_data)\n\n        # Store job status\n        self._redis.hset(\n            f"{self.STATUS_PREFIX}{job_id}",\n            mapping={\n                "status": JobStatus.PENDING,\n                "attempts": "0",\n                "created_at": str(job.created_at),\n                "type": job_type,\n            },\n        )\n        self._redis.expire(f"{self.STATUS_PREFIX}{job_id}", 86400 * 7)  # 7 day TTL\n\n        logger.debug(f"Enqueued job {job_id} to stream {stream}")\n        return job_id\n\n    def dequeue(self, job_types: list[str], timeout: int = 10) -> dict[str, Any] | None:\n        """Dequeue a job from Redis Streams."""\n        # Build list of streams to read from (in priority order)\n        streams = {}\n        for job_type in job_types:\n            for priority in ["high", "normal", "low"]:\n                stream = f"{self.STREAM_PREFIX}{job_type}:{priority}"\n                streams[stream] = ">"  # Read new messages\n\n        if not streams:\n            return None\n\n        try:\n            # First, try to claim stale messages (pending too long)\n            reclaimed = self._claim_stale_messages(job_types)\n            if reclaimed:\n                return reclaimed\n\n            # Read new messages\n            result = self._redis.xreadgroup(\n                self.CONSUMER_GROUP,\n                self._consumer_name,\n                streams,\n                count=1,\n                block=self._block_timeout,\n            )\n\n            if not result:\n                return None\n\n            # Parse result: [(stream_name, [(message_id, {data})])]\n            stream_name, messages = result[0]\n            if not messages:\n                return None\n\n            message_id, data = messages[0]\n\n            job_id = data["id"]\n            job_type = data["type"]\n            payload = json.loads(data["payload"])\n\n            # Update job status\n            attempts = self._redis.hincrby(\n                f"{self.STATUS_PREFIX}{job_id}", "attempts", 1\n            )\n            self._redis.hset(\n                f"{self.STATUS_PREFIX}{job_id}",\n                mapping={\n                    "status": JobStatus.PROCESSING,\n                    "started_at": str(time.time()),\n                    "message_id": message_id,\n                    "stream": stream_name,\n                    "consumer": self._consumer_name,\n                },\n            )\n\n            return {\n                "id": job_id,\n                "type": job_type,\n                "payload": payload,\n                "priority": int(data.get("priority", 0)),\n                "attempts": attempts,\n                "_message_id": message_id,\n                "_stream": stream_name,\n            }\n\n        except Exception as e:\n            logger.error(f"Error dequeuing from Redis: {e}")\n            return None\n\n    def _claim_stale_messages(self, job_types: list[str]) -> dict[str, Any] | None:\n        """Attempt to claim stale (pending too long) messages."""\n        min_idle_time = self._visibility_timeout * 1000  # Convert to ms\n\n        for job_type in job_types:\n            for priority in ["high", "normal", "low"]:\n                stream = f"{self.STREAM_PREFIX}{job_type}:{priority}"\n                try:\n                    pending = self._redis.xpending_range(\n                        stream, self.CONSUMER_GROUP, min="-", max="+", count=10\n                    )\n                    for entry in pending:\n                        if entry.get("time_since_delivered", 0) >= min_idle_time:\n                            job = self._process_stale_message(\n                                stream, entry["message_id"], min_idle_time\n                            )\n                            if job:\n                                return job\n                except Exception as e:\n                    logger.warning(f"Error claiming stale messages from {stream}: {e}")\n\n        return None\n\n    def _process_stale_message(\n        self, stream: str, msg_id: str, min_idle_time: int\n    ) -> dict[str, Any] | None:\n        """Process a single stale message."""\n        claimed = self._redis.xclaim(\n            stream,\n            self.CONSUMER_GROUP,\n            self._consumer_name,\n            min_idle_time=min_idle_time,\n            message_ids=[msg_id],\n        )\n\n        if not claimed:\n            return None\n\n        msg_id, data = claimed[0]\n        job_id = data["id"]\n        attempts = int(\n            self._redis.hget(f"{self.STATUS_PREFIX}{job_id}", "attempts") or 0\n        )\n\n        if attempts >= self._max_retries:\n            self._move_to_dead_letter(job_id, stream, msg_id, data)\n            return None\n\n        # Update status and return\n        self._redis.hincrby(f"{self.STATUS_PREFIX}{job_id}", "attempts", 1)\n        self._redis.hset(\n            f"{self.STATUS_PREFIX}{job_id}",\n            mapping={\n                "status": JobStatus.PROCESSING,\n                "started_at": str(time.time()),\n                "message_id": msg_id,\n                "stream": stream,\n                "consumer": self._consumer_name,\n            },\n        )\n\n        return {\n            "id": job_id,\n            "type": data["type"],\n            "payload": json.loads(data["payload"]),\n            "priority": int(data.get("priority", 0)),\n            "attempts": attempts + 1,\n            "_message_id": msg_id,\n            "_stream": stream,\n        }\n\n    def _move_to_dead_letter(\n        self, job_id: str, stream: str, message_id: str, data: dict[str, Any]\n    ) -> None:\n        """Move a failed job to the dead letter queue."""\n        # Add to dead letter stream\n        dead_data = {\n            **data,\n            "original_stream": stream,\n            "original_message_id": message_id,\n            "dead_letter_at": str(time.time()),\n        }\n        self._redis.xadd(self.DEAD_LETTER_STREAM, dead_data)\n\n        # Acknowledge original message\n        self._redis.xack(stream, self.CONSUMER_GROUP, message_id)\n\n        # Update status\n        self._redis.hset(\n            f"{self.STATUS_PREFIX}{job_id}",\n            mapping={\n                "status": JobStatus.DEAD_LETTER,\n                "dead_letter_at": str(time.time()),\n            },\n        )\n\n        logger.warning(f"Job {job_id} moved to dead letter queue")\n\n    def ack(self, job_id: str) -> None:\n        """Acknowledge job completion."""\n        status_key = f"{self.STATUS_PREFIX}{job_id}"\n        status_data = self._redis.hgetall(status_key)\n\n        if not status_data:\n            logger.warning(f"Job {job_id} not found for ack")\n            return\n\n        stream = status_data.get("stream")\n        message_id = status_data.get("message_id")\n\n        if stream and message_id:\n            self._redis.xack(stream, self.CONSUMER_GROUP, message_id)\n\n        # Update status\n        self._redis.hset(\n            status_key,\n            mapping={\n                "status": JobStatus.COMPLETED,\n                "completed_at": str(time.time()),\n            },\n        )\n\n        logger.debug(f"Acknowledged job {job_id}")\n\n    def nack(self, job_id: str, error: str | None = None) -> None:\n        """\n        Negative acknowledge (fail/retry).\n\n        If retries are exhausted, moves the job to the dead-letter queue.\n        Otherwise, the job remains in the pending queue to be re-claimed later.\n        The `_claim_stale_messages` logic handles re-delivery.\n        """\n        status_key = f"{self.STATUS_PREFIX}{job_id}"\n        status_data = self._redis.hgetall(status_key)\n\n        if not status_data:\n            logger.warning(f"Job {job_id} not found for nack")\n            return\n\n        attempts = int(status_data.get("attempts", 0))\n\n        if attempts >= self._max_retries:\n            self._handle_max_retries(job_id, status_data, status_key, error)\n        else:\n            self._redis.hset(\n                status_key,\n                mapping={\n                    "status": JobStatus.PENDING,\n                    "error": error or "",\n                    "last_failed_at": str(time.time()),\n                },\n            )\n            logger.debug(f"Nacked job {job_id} (attempt {attempts}). Will be retried.")\n\n    def _handle_max_retries(\n        self,\n        job_id: str,\n        status_data: dict[str, Any],\n        status_key: str,\n        error: str | None,\n    ) -> None:\n        """Handle a job that has reached its maximum number of retries."""\n        stream = status_data.get("stream")\n        message_id = status_data.get("message_id")\n\n        if stream and message_id:\n            data = self._redis.xrange(stream, min=message_id, max=message_id, count=1)\n            if data:\n                _, job_data = data[0]\n                self._move_to_dead_letter(job_id, stream, message_id, job_data)\n            else:\n                logger.warning(\n                    f"Could not find message {message_id} in stream {stream} for job {job_id} to dead-letter."\n                )\n                self._redis.hset(\n                    status_key,\n                    mapping={\n                        "status": JobStatus.DEAD_LETTER,\n                        "error": error or "Max retries exceeded (message not found)",\n                    },\n                )\n        else:\n            self._redis.hset(\n                status_key,\n                mapping={\n                    "status": JobStatus.DEAD_LETTER,\n                    "error": error or "Max retries exceeded (no stream info)",\n                },\n            )\n\n    def get_job_status(self, job_id: str) -> dict[str, Any] | None:\n        """Get job status."""\n        status_data = self._redis.hgetall(f"{self.STATUS_PREFIX}{job_id}")\n        if not status_data:\n            return None\n\n        return {\n            "id": job_id,\n            "status": status_data.get("status"),\n            "attempts": int(status_data.get("attempts", 0)),\n            "created_at": float(status_data.get("created_at", 0)),\n            "started_at": (\n                float(status_data.get("started_at", 0))\n                if status_data.get("started_at")\n                else None\n            ),\n            "completed_at": (\n                float(status_data.get("completed_at", 0))\n                if status_data.get("completed_at")\n                else None\n            ),\n            "error": status_data.get("error"),\n            "type": status_data.get("type"),\n        }\n\n    def get_queue_stats(self) -> dict[str, int]:\n        """Get queue statistics."""\n        stats = {\n            "pending": 0,\n            "processing": 0,\n            "completed": 0,\n            "dead_letter": 0,\n        }\n\n        # Count dead letter messages\n        try:\n            dl_info = self._redis.xinfo_stream(self.DEAD_LETTER_STREAM)\n            stats["dead_letter"] = dl_info.get("length", 0)\n        except Exception:\n            pass\n\n        # Count messages in job streams\n        job_types_to_scan = self._job_types or []\n        if not job_types_to_scan:\n            logger.warning(\n                "Cannot get complete queue stats, job types not provided at init."\n            )\n        for job_type in job_types_to_scan:\n            for priority in ["high", "normal", "low"]:\n                stream = f"{self.STREAM_PREFIX}{job_type}:{priority}"\n                try:\n                    info = self._redis.xinfo_stream(stream)\n                    stats["pending"] += info.get("length", 0)\n\n                    # Get consumer group info for processing count\n                    groups = self._redis.xinfo_groups(stream)\n                    for group in groups:\n                        if group["name"] == self.CONSUMER_GROUP:\n                            stats["processing"] += group.get("pending", 0)\n                except Exception:\n                    pass\n\n        return stats\n\n    def cleanup_completed(self, max_age_seconds: int = 86400) -> int:\n        """\n        Clean up completed job status records.\n\n        Args:\n            max_age_seconds: Maximum age of completed jobs to keep\n\n        Returns:\n            Number of records cleaned up\n        """\n        # This is a maintenance operation - scan status keys and remove old completed ones\n        cleaned = 0\n        cursor = "0"\n        cutoff = time.time() - max_age_seconds\n\n        while True:\n            cursor, keys = self._redis.scan(\n                cursor=cursor, match=f"{self.STATUS_PREFIX}*", count=100\n            )\n\n            for key in keys:\n                status_data = self._redis.hgetall(key)\n                if status_data.get("status") == JobStatus.COMPLETED:\n                    completed_at = float(status_data.get("completed_at", 0))\n                    if completed_at < cutoff:\n                        self._redis.delete(key)\n                        cleaned += 1\n\n            if cursor == "0":\n                break\n\n        if cleaned > 0:\n            logger.info(f"Cleaned up {cleaned} completed job records")\n\n        return cleaned\n\n\n# -----------------------------------------------------------------------------\n# Celery-Based Queue (Alternative Production Backend)\n# -----------------------------------------------------------------------------\n\n\nclass CeleryQueue(JobQueue):\n    """\n    Celery-based job queue for production use.\n\n    Provides an alternative to Redis Streams using Celery for\n    task distribution and result tracking.\n    """\n\n    def __init__(\n        self,\n        broker_url: str = "redis://localhost:6379/0",\n        job_types: list[str] | None = None,\n    ):\n        """\n        Initialize Celery queue.\n\n        Args:\n            broker_url: Celery broker URL (Redis, RabbitMQ, etc.)\n            job_types: List of job types to register as tasks\n        """\n        try:\n            from celery import Celery\n        except ImportError:\n            raise ImportError(\n                "celery package required for CeleryQueue. "\n                "Install with: pip install celery[redis]"\n            )\n\n        self._app = Celery("cortex", broker=broker_url)\n        self._app.conf.update(\n            task_serializer="json",\n            result_serializer="json",\n            accept_content=["json"],\n            result_expires=86400,  # 1 day\n            task_acks_late=True,\n            task_reject_on_worker_lost=True,\n        )\n        self._pending_jobs: dict[str, dict[str, Any]] = {}\n        self._lock = threading.Lock()\n        self._job_types = job_types or []\n        self._task_map: dict[str, Any] = {}\n\n        # Register task handlers\n        self._register_tasks()\n\n        logger.info("CeleryQueue initialized")\n\n    def _register_tasks(self) -> None:\n        """Register Celery tasks for job types."""\n\n        def create_task(name):\n            @self._app.task(name=f"cortex.{name}", bind=True, max_retries=3)\n            def generic_task(self, payload: dict[str, Any]) -> dict[str, Any]:\n                # Worker-side logic would go here.\n                # For this abstraction, we just return a success marker.\n                return {"status": "completed", "payload": payload}\n\n            return generic_task\n\n        for job_type in self._job_types:\n            self._task_map[job_type] = create_task(job_type)\n\n    def enqueue(self, job_type: str, payload: dict[str, Any], priority: int = 0) -> str:\n        """Enqueue a job via Celery."""\n        job_id = str(uuid.uuid4())\n\n        task = self._task_map.get(job_type)\n        if not task:\n            raise ValueError(f"Unknown or unregistered job type for Celery: {job_type}")\n\n        # Calculate Celery priority (0-9, lower = higher priority)\n        celery_priority = max(0, min(9, 5 - (priority // 2)))\n\n        result = task.apply_async(\n            args=[payload],\n            task_id=job_id,\n            priority=celery_priority,\n        )\n\n        with self._lock:\n            self._pending_jobs[job_id] = {\n                "id": job_id,\n                "type": job_type,\n                "payload": payload,\n                "priority": priority,\n                "result": result,\n            }\n\n        logger.debug(f"Enqueued Celery task {job_id} of type {job_type}")\n        return job_id\n\n    def dequeue(self, job_types: list[str], timeout: int = 10) -> dict[str, Any] | None:\n        """\n        Dequeue is handled by Celery workers automatically.\n        This method is not used in a Celery-based setup and is here for ABC compliance.\n        """\n        logger.debug(\n            "CeleryQueue.dequeue called but is a no-op; workers handle dequeuing."\n        )\n        # Block for a short time to simulate waiting, but Celery workers operate independently.\n        time.sleep(timeout)\n        return None\n\n    def ack(self, job_id: str) -> None:\n        """Acknowledge job completion (handled automatically by Celery)."""\n        with self._lock:\n            if job_id in self._pending_jobs:\n                del self._pending_jobs[job_id]\n        logger.debug(f"Acknowledged Celery task {job_id}")\n\n    def nack(self, job_id: str, error: str | None = None) -> None:\n        """Negative acknowledge - Celery handles retries automatically."""\n        logger.debug(f"Nack Celery task {job_id}: {error}")\n\n    def get_job_status(self, job_id: str) -> dict[str, Any] | None:\n        """Get job status via Celery AsyncResult."""\n        from celery.result import AsyncResult\n\n        result = AsyncResult(job_id, app=self._app)\n\n        status_map = {\n            "PENDING": JobStatus.PENDING,\n            "STARTED": JobStatus.PROCESSING,\n            "SUCCESS": JobStatus.COMPLETED,\n            "FAILURE": JobStatus.FAILED,\n            "RETRY": JobStatus.PENDING,\n        }\n\n        return {\n            "id": job_id,\n            "status": status_map.get(result.status, JobStatus.PENDING),\n            "result": result.result if result.ready() else None,\n            "error": str(result.result) if result.failed() else None,\n        }\n\n    def get_queue_stats(self) -> dict[str, int]:\n        """Get queue statistics."""\n        # Celery queue inspection requires the inspect API\n        try:\n            inspector = self._app.control.inspect()\n            active = inspector.active() or {}\n            reserved = inspector.reserved() or {}\n            scheduled = inspector.scheduled() or {}\n\n            return {\n                "pending": sum(len(v) for v in reserved.values())\n                + sum(len(v) for v in scheduled.values()),\n                "processing": sum(len(v) for v in active.values()),\n                "completed": 0,  # Would need result backend query\n                "failed": 0,\n            }\n        except Exception as e:\n            logger.warning(f"Failed to get Celery stats: {e}")\n            return {"pending": 0, "processing": 0, "completed": 0, "failed": 0}\n\n\n# -----------------------------------------------------------------------------\n# Queue Factory\n# -----------------------------------------------------------------------------\n\n_queue_instance: JobQueue | None = None\n_queue_lock = threading.Lock()\n\n\ndef get_queue(job_types: list[str] | None = None) -> JobQueue:\n    """\n    Get the configured queue instance.\n\n    Uses config to determine queue type:\n    - 'redis': RedisStreamsQueue (default production)\n    - 'celery': CeleryQueue (alternative production)\n    - 'memory': InMemoryQueue (testing only)\n\n    Args:\n        job_types (Optional[list[str]]): For Redis, a list of all job types to ensure\n                                         consumer groups are created. This is only\n                                         needed by worker processes.\n    """\n    global _queue_instance\n\n    with _queue_lock:\n        if _queue_instance is None:\n            from cortex.config.loader import get_config\n            from cortex.queue_registry import get_known_job_types\n\n            config = get_config()\n            job_types = get_known_job_types()\n\n            # Check for queue type in config (default to redis for production)\n            queue_type = getattr(config.system, "queue_type", "redis")\n\n            if queue_type == "redis":\n                try:\n                    redis_url = os.getenv(\n                        "OUTLOOKCORTEX_REDIS_URL", "redis://localhost:6379"\n                    )\n                    # For workers, this will create consumer groups. For producers, it can be an empty list.\n                    all_job_types = job_types or []\n                    _queue_instance = RedisStreamsQueue(\n                        redis_url=redis_url, job_types=all_job_types\n                    )\n                    logger.info("Initialized Redis Streams queue")\n                except ImportError as e:\n                    raise ImportError(\n                        f"Redis package required for production queue: {e}. "\n                        "Install with: pip install redis"\n                    )\n                except Exception as e:\n                    raise RuntimeError(\n                        f"Failed to initialize Redis queue: {e}. "\n                        "Ensure Redis is running and accessible."\n                    )\n\n            elif queue_type == "celery":\n                try:\n                    broker_url = os.getenv(\n                        "OUTLOOKCORTEX_CELERY_BROKER", "redis://localhost:6379/0"\n                    )\n                    _queue_instance = CeleryQueue(\n                        broker_url=broker_url, job_types=job_types\n                    )\n                    logger.info("Initialized Celery queue")\n                except ImportError as e:\n                    raise ImportError(\n                        f"Celery package required: {e}. "\n                        "Install with: pip install celery[redis]"\n                    )\n                except Exception as e:\n                    raise RuntimeError(f"Failed to initialize Celery queue: {e}")\n            elif queue_type == "memory":\n                logger.warning(\n                    "Using InMemoryQueue. This should only be used for testing purposes."\n                )\n                _queue_instance = InMemoryQueue()\n            else:\n                raise ValueError(\n                    f"Unknown queue type: {queue_type}. Valid options: redis, celery, memory"\n                )\n\n    return _queue_instance\n\n\ndef reset_queue() -> None:\n    """Reset the queue instance (useful for testing)."""\n    global _queue_instance\n    with _queue_lock:\n        _queue_instance = None\n