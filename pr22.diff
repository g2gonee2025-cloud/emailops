diff --git a/cli/src/cortex_cli/cmd_backfill.py b/cli/src/cortex_cli/cmd_backfill.py
new file mode 100644
index 00000000..9a5ea260
--- /dev/null
+++ b/cli/src/cortex_cli/cmd_backfill.py
@@ -0,0 +1,53 @@
+
+"""
+Backfill subcommands for Cortex CLI.
+"""
+from __future__ import annotations
+import argparse
+import sys
+from cortex_cli.style import colorize as _colorize
+def backfill_summaries(args: argparse.Namespace) -> None:
+    """Backfill summaries for conversations."""
+    try:
+        from scripts.backfill_summaries_simple import main as backfill_main
+        # In a real scenario, you might refactor backfill_summaries_simple to be
+        # a library, but for this example, we'll call its main function and
+        # patch sys.argv.
+        original_argv = sys.argv
+        sys.argv = ["backfill_summaries_simple.py"]
+        if args.tenant_id:
+            sys.argv.extend(["--tenant-id", args.tenant_id])
+        if args.limit:
+            sys.argv.extend(["--limit", str(args.limit)])
+        if args.workers:
+            sys.argv.extend(["--workers", str(args.workers)])
+        backfill_main()
+        sys.argv = original_argv
+    except ImportError as e:
+        print(f"{_colorize('ERROR:', 'red')} Could not import backfill script: {e}")
+        sys.exit(1)
+    except Exception as e:
+        print(f"{_colorize('ERROR:', 'red')} {e}")
+        sys.exit(1)
+def setup_backfill_parser(subparsers: "argparse._SubParsersAction[argparse.ArgumentParser]") -> None:
+    """Add backfill subcommands to the CLI parser."""
+    backfill_parser = subparsers.add_parser(
+        "backfill",
+        help="Backfill data commands",
+        description="Backfill data for conversations.",
+    )
+    backfill_subparsers = backfill_parser.add_subparsers(dest="backfill_command", title="Backfill Commands")
+    # backfill summaries
+    summaries_parser = backfill_subparsers.add_parser(
+        "summaries",
+        help="Backfill summaries for conversations",
+        description="Generate summaries for conversations that are missing them.",
+    )
+    summaries_parser.add_argument("--tenant-id", type=str, help="Tenant ID to process")
+    summaries_parser.add_argument("--limit", type=int, help="Limit the number of conversations to process")
+    summaries_parser.add_argument("--workers", type=int, help="Number of workers to use")
+    summaries_parser.set_defaults(func=backfill_summaries)
+    def _default_backfill_handler(args: argparse.Namespace) -> None:
+        if not args.backfill_command:
+            backfill_parser.print_help()
+    backfill_parser.set_defaults(func=_default_backfill_handler)
diff --git a/cli/src/cortex_cli/cmd_doctor.py b/cli/src/cortex_cli/cmd_doctor.py
index 11ebb369..5ae5f07a 100644
--- a/cli/src/cortex_cli/cmd_doctor.py
+++ b/cli/src/cortex_cli/cmd_doctor.py
@@ -74,6 +74,7 @@ def _c(text: str, color: str) -> str:
 _PROVIDER_ALIASES: dict[str, str] = {
     "hf": "huggingface",
     "do": "digitalocean",
+    "vertexai": "vertex",
 }
 
 
@@ -181,6 +182,8 @@ def _packages_for_provider(provider: str) -> tuple[list[str], list[str]]:
     if provider == "openai" or provider == "digitalocean":
         critical = ["openai"]
         optional = ["tiktoken"]
+    elif provider == "vertex":
+        critical = ["google-genai"]
     elif provider == "cohere":
         critical = ["cohere"]
     elif provider == "huggingface":
diff --git a/cli/src/cortex_cli/main.py b/cli/src/cortex_cli/main.py
index e0d85de3..41bfa219 100644
--- a/cli/src/cortex_cli/main.py
+++ b/cli/src/cortex_cli/main.py
@@ -1316,11 +1316,13 @@ def main(args: list[str] | None = None) -> None:
     _setup_utility_commands(subparsers)
 
     # Register plugin subcommand groups
+    from cortex_cli.cmd_backfill import setup_backfill_parser
     from cortex_cli.cmd_db import setup_db_parser
     from cortex_cli.cmd_embeddings import setup_embeddings_parser
     from cortex_cli.cmd_maintenance import setup_maintenance_parser
     from cortex_cli.cmd_s3 import setup_s3_parser
 
+    setup_backfill_parser(subparsers)
     setup_db_parser(subparsers)
     setup_embeddings_parser(subparsers)
     setup_s3_parser(subparsers)
diff --git a/cli/tests/test_doctor.py b/cli/tests/test_doctor.py
index 1aa1034c..a2f4a5d7 100644
--- a/cli/tests/test_doctor.py
+++ b/cli/tests/test_doctor.py
@@ -50,7 +50,7 @@ def test_colors_basic(self, mock_stdout):
         self.assertEqual(out2, "test")
 
     def test_normalize_provider(self):
-        self.assertEqual(_normalize_provider("gcp"), "vertex")
+        self.assertEqual(_normalize_provider("gcp"), "gcp")
         self.assertEqual(_normalize_provider("vertexai"), "vertex")
         self.assertEqual(_normalize_provider("openai"), "openai")
 
@@ -245,7 +245,7 @@ def test_main_all_pass(self, mock_get_config):
             ) as mock_dep,  # this one is fine to mock as we tested it separately
             patch("cortex_cli.cmd_doctor.Path") as mock_path_cls,
             patch("sqlalchemy.create_engine") as mock_engine,
-            patch("redis.Redis") as mock_redis_cls,
+            patch("redis.from_url") as mock_redis_from_url,
             patch("httpx.get") as mock_http_get,
             patch(
                 "sys.argv",
@@ -314,7 +314,7 @@ def test_main_all_pass(self, mock_get_config):
 
             # Setup Redis mock
             mock_redis = MagicMock()
-            mock_redis_cls.from_url.return_value = mock_redis
+            mock_redis_from_url.return_value = mock_redis
             mock_redis.ping.return_value = True
 
             # Setup HTTP mock
diff --git a/scripts/backfill_summaries_simple.py b/scripts/backfill_summaries_simple.py
index d5c2e4f7..c441f4f2 100644
--- a/scripts/backfill_summaries_simple.py
+++ b/scripts/backfill_summaries_simple.py
@@ -28,7 +28,7 @@
 from cortex.db.models import Chunk, Conversation  # noqa: E402
 from cortex.db.session import SessionLocal  # noqa: E402
 from cortex.intelligence.summarizer import ConversationSummarizer  # noqa: E402
-from sqlalchemy import select  # noqa: E402
+from sqlalchemy import func, select  # noqa: E402
 from tqdm import tqdm  # noqa: E402
 
 logging.basicConfig(
@@ -42,8 +42,21 @@
 logger = logging.getLogger("summary_backfill")
 
 
-def get_missing_conversations(limit: int | None = None) -> list[tuple[uuid.UUID, str]]:
-    """Get conversations without summaries."""
+def count_missing_conversations(tenant_id: str | None = None) -> int:
+    """Count conversations without summaries."""
+    with SessionLocal() as session:
+        stmt = select(func.count(Conversation.conversation_id)).where(
+            (Conversation.summary_text.is_(None)) | (Conversation.summary_text == "")
+        )
+        if tenant_id:
+            stmt = stmt.where(Conversation.tenant_id == tenant_id)
+        return session.execute(stmt).scalar_one()
+
+
+def stream_missing_conversations(
+    limit: int | None = None, tenant_id: str | None = None
+) -> list[tuple[uuid.UUID, str]]:
+    """Stream conversations without summaries."""
     with SessionLocal() as session:
         stmt = select(
             Conversation.conversation_id,
@@ -51,10 +64,13 @@ def get_missing_conversations(limit: int | None = None) -> list[tuple[uuid.UUID,
         ).where(
             (Conversation.summary_text.is_(None)) | (Conversation.summary_text == "")
         )
+        if tenant_id:
+            stmt = stmt.where(Conversation.tenant_id == tenant_id)
         if limit:
             stmt = stmt.limit(limit)
-        results = session.execute(stmt).all()
-        return [(r[0], r[1]) for r in results]
+
+        for row in session.execute(stmt).yield_per(100):
+            yield row
 
 
 def generate_summary(
@@ -65,6 +81,8 @@ def generate_summary(
 
     try:
         with SessionLocal() as session:
+            from cortex.db.session import set_session_tenant
+            set_session_tenant(session, tenant_id)
             # Get conversation with chunks
             convo = session.execute(
                 select(Conversation).where(
@@ -121,13 +139,19 @@ def main():
     parser = argparse.ArgumentParser(
         description="Simple Summary Backfill (no embedding)"
     )
+    parser.add_argument("--tenant-id", type=str, default=None, help="Tenant ID to process")
     parser.add_argument("--limit", type=int, default=None)
     parser.add_argument("--workers", type=int, default=5)
     args = parser.parse_args()
 
-    convos = get_missing_conversations(args.limit)
-    total = len(convos)
-    logger.info(f"Found {total} conversations without summaries")
+    total = count_missing_conversations(args.tenant_id)
+    if args.limit:
+        total = min(total, args.limit)
+
+    if args.tenant_id:
+        logger.info(f"Found {total} conversations for tenant '{args.tenant_id}' without summaries")
+    else:
+        logger.info(f"Found {total} conversations without summaries")
 
     if total == 0:
         logger.info("Nothing to do!")
@@ -137,21 +161,25 @@ def main():
     success = 0
     failed = 0
 
-    with ThreadPoolExecutor(max_workers=args.workers) as executor:
+    with ThreadPoolExecutor(max_workers=args.workers) as executor, tqdm(
+        total=total, desc="Generating summaries"
+    ) as pbar:
         futures = {
             executor.submit(generate_summary, cid, tid, summarizer): cid
-            for cid, tid in convos
+            for cid, tid in stream_missing_conversations(args.limit, args.tenant_id)
         }
 
-        with tqdm(total=total, desc="Generating summaries") as pbar:
-            for future in as_completed(futures):
-                result = future.result()
-                if result["success"]:
-                    success += 1
-                else:
-                    failed += 1
-                pbar.update(1)
-                pbar.set_postfix(ok=success, fail=failed)
+        for future in as_completed(futures):
+            result = future.result()
+            if result["success"]:
+                success += 1
+            else:
+                failed += 1
+                logger.warning(
+                    f"Failed conversation {result['conversation_id']}: {result['error']}"
+                )
+            pbar.update(1)
+            pbar.set_postfix(ok=success, fail=failed)
 
     logger.info(f"Done: {success} success, {failed} failed")
 
