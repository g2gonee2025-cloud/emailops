diff --git a/backend/src/cortex/ingestion/conv_manifest/validation.py b/backend/src/cortex/ingestion/conv_manifest/validation.py
index af130e23..f3ebe9fb 100644
--- a/backend/src/cortex/ingestion/conv_manifest/validation.py
+++ b/backend/src/cortex/ingestion/conv_manifest/validation.py
@@ -12,7 +12,7 @@
 from pathlib import Path
 from typing import Any, Dict, List, Optional
 
-from cortex.ingestion.core_manifest import load_manifest
+from cortex.ingestion.core_manifest import extract_metadata_lightweight, load_manifest
 from cortex.ingestion.models import Problem
 from cortex.utils.atomic_io import atomic_write_json
 from pydantic import BaseModel, Field
@@ -96,33 +96,36 @@ def scan_and_refresh(root: Path) -> ManifestValidationReport:
             if manifest_issue:
                 report.problems.append(Problem(folder=folder_rel, issue=manifest_issue))
 
-        conv_start, conv_end = _extract_conversation_time_range(conv_txt)
+        # Use the canonical metadata extractor
+        metadata = extract_metadata_lightweight(existing_manifest)
         mtime_iso = _file_mtime_iso(conv_txt)
 
-        # Extract participants from text as fallback/enrichment
-        participants = _extract_participants_from_txt(conv_txt)
-        last_from, last_to = _extract_last_message_participants(conv_txt)
-
         # Build new manifest with idempotent timestamps derived from manifest -> convo text -> mtime
         started_at = _preserve_str(
-            existing_manifest.get("started_at_utc"), conv_start or mtime_iso
+            existing_manifest.get("started_at_utc"), metadata.get("start_date") or mtime_iso
         )
         ended_at = _preserve_str(
-            existing_manifest.get("ended_at_utc"), conv_end or started_at
+            existing_manifest.get("ended_at_utc"), metadata.get("end_date") or started_at
         )
 
         # Start with a copy to preserve 'messages', 'participants', etc.
         new_manifest = existing_manifest.copy()
+        all_participants = metadata.get("from", []) + metadata.get("to", []) + metadata.get("cc", [])
+        # Extract email (index 1 of tuple), filter out empty ones, ensure uniqueness, and sort
+        participant_emails = sorted(
+            list(set(p[1] for p in all_participants if p and p[1])),
+            key=str.lower
+        )
         new_manifest.update(
             {
                 "manifest_version": "1",
                 "folder": folder_rel,
                 "subject_label": _preserve_str(
-                    existing_manifest.get("subject_label"), folder_rel
+                    existing_manifest.get("subject_label"), metadata.get("subject") or folder_rel
                 ),
-                "participants": participants,  # Explicitly added
-                "last_from": last_from,
-                "last_to": last_to,
+                "participants": participant_emails,
+                "last_from": (metadata.get("from")[-1] if metadata.get("from") else [("", "")])[-1][1],
+                "last_to": [p[1] for p in metadata.get("to", [])],
                 "message_count": existing_manifest.get("message_count", 0),
                 "started_at_utc": started_at,
                 "ended_at_utc": ended_at,
@@ -218,111 +221,3 @@ def _preserve_str(value: Any, fallback: str) -> str:
     if isinstance(value, str) and value.strip():
         return value
     return fallback
-
-
-def _extract_conversation_time_range(conv_txt: Path) -> tuple[str | None, str | None]:
-    """Extract min/max message timestamps from Conversation.txt content."""
-    try:
-        text = conv_txt.read_text(encoding="utf-8-sig", errors="replace")
-    except Exception:
-        return None, None
-
-    fmt_candidates = ["%Y-%m-%d %H:%M:%S", "%Y-%m-%d %H:%M"]
-    earliest: datetime | None = None
-    latest: datetime | None = None
-
-    for line in text.splitlines():
-        # Cheap scan: look for tokens that resemble timestamps (date and time separated by space or T)
-        tokens = line.replace("T", " ").split()
-        for token in tokens:
-            if len(token) < 16:
-                continue
-            for fmt in fmt_candidates:
-                try:
-                    if len(token) == 16 and fmt.endswith("%S"):
-                        continue
-                    dt = datetime.strptime(token, fmt).replace(tzinfo=timezone.utc)
-                    if earliest is None or dt < earliest:
-                        earliest = dt
-                    if latest is None or dt > latest:
-                        latest = dt
-                    break
-                except Exception:
-                    continue
-
-    def to_iso(dt: datetime | None) -> str | None:
-        if dt is None:
-            return None
-        return dt.strftime("%Y-%m-%dT%H:%M:%SZ")
-
-    return to_iso(earliest), to_iso(latest)
-
-
-def _extract_participants_from_txt(conv_txt: Path) -> List[str]:
-    """
-    Extract participant names/emails from headers in Conversation.txt.
-
-    Delegates to the Single Source of Truth in conversation_parser.py.
-
-    Args:
-        conv_txt: Path to Conversation.txt
-
-    Returns:
-        List of distinct participant strings (sorted, plain email addresses)
-    """
-    try:
-        from cortex.ingestion.conversation_parser import (
-            extract_participants_from_conversation_txt,
-        )
-
-        text = conv_txt.read_text(encoding="utf-8-sig", errors="replace")
-        participants = extract_participants_from_conversation_txt(text)
-
-        # Validation manifest expects a flat list of plain email addresses
-        # Extract just the smtp field for backward compatibility
-        results = set()
-        for p in participants:
-            if p.get("smtp"):
-                results.add(p["smtp"])
-
-        return sorted(list(results), key=str.lower)
-
-    except Exception as e:
-        logger.warning(f"Failed to extract participants from {conv_txt}: {e}")
-        return []
-
-
-def _extract_last_message_participants(
-    conv_txt: Path,
-) -> tuple[Optional[str], List[str]]:
-    """Extract the sender (From) and recipients (To) of the last message in the conversation.
-
-    The Conversation.txt format typically contains lines like:
-        2024-10-07 14:43 | From: alice@example.com | To: bob@example.com; carol@example.com
-    This function finds the last such line and returns the From address and a list of To addresses.
-    """
-    import re
-
-    last_from: Optional[str] = None
-    last_to: List[str] = []
-    try:
-        text = conv_txt.read_text(encoding="utf-8-sig", errors="replace")
-        # Process lines in reverse to find the last line containing From and To
-        for line in reversed(text.splitlines()):
-            if "From:" in line and "To:" in line:
-                parts = [p.strip() for p in line.split("|")]
-                from_part = next((p for p in parts if p.startswith("From:")), None)
-                to_part = next((p for p in parts if p.startswith("To:")), None)
-                if from_part and to_part:
-                    last_from = from_part.split(":", 1)[1].strip()
-                    to_raw = to_part.split(":", 1)[1].strip()
-                    for addr in re.split(r"[;,]", to_raw):
-                        addr = addr.strip()
-                        if addr:
-                            last_to.append(addr)
-                break
-    except Exception as e:
-        logger.warning(
-            f"Failed to extract last message participants from {conv_txt}: {e}"
-        )
-    return last_from, last_to
diff --git a/backend/src/cortex/ingestion/core_manifest.py b/backend/src/cortex/ingestion/core_manifest.py
index e4a3c7f8..64432619 100644
--- a/backend/src/cortex/ingestion/core_manifest.py
+++ b/backend/src/cortex/ingestion/core_manifest.py
@@ -3,12 +3,13 @@
 import json
 import logging
 import re
+from datetime import datetime, timezone
 from pathlib import Path
 from typing import Any
 
 """
 core_manifest.py - Centralized manifest.json parsing and metadata extraction.
-from typing import Any, Dict
+
 This module provides THE SINGLE SOURCE OF TRUTH for:
 1. Loading manifest.json files (with robust fallback parsing)
 2. Extracting lightweight metadata (for indexing/chunking)
@@ -277,8 +278,6 @@ def _extract_date_range(manifest: dict[str, Any]) -> dict[str, Any]:
 
             dts = _parse_all_dates(msgs)
             if dts:
-                from datetime import timezone
-
                 start_date = min(dts).astimezone(timezone.utc).isoformat()
                 end_date = max(dts).astimezone(timezone.utc).isoformat()
             else:
@@ -291,8 +290,6 @@ def _extract_date_range(manifest: dict[str, Any]) -> dict[str, Any]:
 
 
 def _parse_all_dates(msgs: list[Any]) -> list[Any]:
-    from datetime import datetime
-
     dts: list[datetime] = []
     for msg in msgs:
         if isinstance(msg, dict) and msg.get("date") is not None:
@@ -303,8 +300,6 @@ def _parse_all_dates(msgs: list[Any]) -> list[Any]:
 
 
 def _parse_dt(v: Any) -> Any | None:
-    from datetime import datetime, timezone
-
     if v is None:
         return None
     if isinstance(v, (int, float)):
@@ -428,10 +423,10 @@ def _mk(name: str, email: str, role: str = "other") -> dict[str, str]:
         logger.warning(
             "extract_participants_detailed: Error extracting participants: %s", e
         )
-        return out
+        return []
     except Exception as e:
         logger.error("extract_participants_detailed: Unexpected error: %s", e)
-        return out
+        return []
     # Deduplicate by lowercase email or normalized name; skip empty entries
     seen: set[str] = set()
     deduped: list[dict[str, str]] = []
@@ -445,7 +440,7 @@ def _mk(name: str, email: str, role: str = "other") -> dict[str, str]:
             continue
         seen.add(key)
         deduped.append(p)
-    return deduped[:max_participants] if deduped else []
+    return deduped[:max_participants]
 
 
 # ============================================================================
diff --git a/cli/src/cortex_cli/cmd_doctor.py b/cli/src/cortex_cli/cmd_doctor.py
index 11ebb369..067aec56 100644
--- a/cli/src/cortex_cli/cmd_doctor.py
+++ b/cli/src/cortex_cli/cmd_doctor.py
@@ -74,6 +74,8 @@ def _c(text: str, color: str) -> str:
 _PROVIDER_ALIASES: dict[str, str] = {
     "hf": "huggingface",
     "do": "digitalocean",
+    "gcp": "vertex",
+    "vertexai": "vertex",
 }
 
 
@@ -190,6 +192,8 @@ def _packages_for_provider(provider: str) -> tuple[list[str], list[str]]:
     elif provider == "local":
         critical = ["sentence-transformers"]
         optional = ["torch", "transformers"]
+    elif provider == "vertex":
+        critical = ["google-genai"]
 
     # Common optional packages
     optional.extend(
diff --git a/cli/tests/test_doctor.py b/cli/tests/test_doctor.py
index 1aa1034c..5620a5ed 100644
--- a/cli/tests/test_doctor.py
+++ b/cli/tests/test_doctor.py
@@ -245,7 +245,7 @@ def test_main_all_pass(self, mock_get_config):
             ) as mock_dep,  # this one is fine to mock as we tested it separately
             patch("cortex_cli.cmd_doctor.Path") as mock_path_cls,
             patch("sqlalchemy.create_engine") as mock_engine,
-            patch("redis.Redis") as mock_redis_cls,
+            patch("redis.from_url") as mock_redis_from_url,
             patch("httpx.get") as mock_http_get,
             patch(
                 "sys.argv",
@@ -314,7 +314,7 @@ def test_main_all_pass(self, mock_get_config):
 
             # Setup Redis mock
             mock_redis = MagicMock()
-            mock_redis_cls.from_url.return_value = mock_redis
+            mock_redis_from_url.return_value = mock_redis
             mock_redis.ping.return_value = True
 
             # Setup HTTP mock
diff --git a/reference code/core_manifest.py b/reference code/core_manifest.py
index 2f0a2dc0..64432619 100644
--- a/reference code/core_manifest.py	
+++ b/reference code/core_manifest.py	
@@ -3,7 +3,7 @@
 import json
 import logging
 import re
-from datetime import UTC
+from datetime import datetime, timezone
 from pathlib import Path
 from typing import Any
 
@@ -16,14 +16,85 @@
 3. Extracting detailed participant information (for summarization)
 
 All other modules should import from here instead of duplicating logic.
-
-NOTE: This module returns plain Python dict/tuple structures for maximum compatibility.
 """
 
-logger = logging.getLogger(__name__)
 # Control character pattern
 _CONTROL_CHARS = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]")
 
+# Subject normalization patterns
+_RE_FWD_PATTERN = re.compile(
+    r"^(?:re|fwd?|aw|sv|vs|antw|odp|回复|答复|轉寄):\s*", re.IGNORECASE
+)
+_BRACKET_PATTERN = re.compile(r"\[.*?\]")
+_WHITESPACE_PATTERN = re.compile(r"\s+")
+
+
+def _normalize_subject_helper(subject: str) -> str:
+    """
+    Normalize subject for threading.
+
+    - Remove Re:, Fwd:, FW:, etc. prefixes (in multiple languages)
+    - Remove [bracketed] content like [EXTERNAL]
+    - Collapse whitespace
+    - Lowercase
+    """
+    if not subject:
+        return ""
+
+    # Remove Re/Fwd prefixes iteratively
+    normalized = subject
+    while True:
+        new_val = _RE_FWD_PATTERN.sub("", normalized).strip()
+        if new_val == normalized:
+            break
+        normalized = new_val
+
+    # Remove bracketed content
+    normalized = _BRACKET_PATTERN.sub("", normalized)
+
+    # Collapse whitespace and lowercase
+    normalized = _WHITESPACE_PATTERN.sub(" ", normalized).strip().lower()
+
+    return normalized
+
+
+def normalize_subject(subject: str) -> str:
+    """Public helper that normalizes subjects consistently across modules."""
+    return _normalize_subject_helper(subject)
+
+
+logger = logging.getLogger(__name__)
+
+
+def parse_manifest_text(text: str, source: str = "<unknown>") -> dict[str, Any]:
+    """
+    Parse manifest JSON text with robust fallback strategies.
+
+    Args:
+        text: Raw JSON text (utf-8 decoded)
+        source: Source identifier for logging (e.g. filename/key)
+
+    Returns:
+        Parsed manifest dict, or {} if parsing fails
+    """
+    if not text:
+        return {}
+
+    # Aggressive sanitization
+    sanitized = _CONTROL_CHARS.sub("", text)
+
+    try:
+        # 1) Try strict JSON first
+        return dict(json.loads(sanitized))
+    except (json.JSONDecodeError, TypeError):
+        # 2) Apply backslash repair
+        repaired = re.sub(r'(?<!\\)\\(?!["\\/bfnrtu])', r"\\\\", sanitized)
+        try:
+            return dict(json.loads(repaired))
+        except json.JSONDecodeError as e:
+            logger.error("Failed to parse manifest from %s: %s", source, e)
+            return {}
+
 
 # ============================================================================
 # Manifest File Loading (Canonical with Robust Fallbacks)
@@ -64,12 +135,12 @@ def load_manifest(convo_dir: Path) -> dict[str, Any]:
         sanitized = _CONTROL_CHARS.sub("", raw_text)
         # 1) Try strict JSON first (no repair)
         try:
-            return json.loads(sanitized)
-        except json.JSONDecodeError:
+            return dict(json.loads(sanitized))
+        except (json.JSONDecodeError, TypeError):
             # 2) Apply backslash repair then try JSON again
             repaired = re.sub(r'(?<!\\)\\(?!["\\/bfnrtu])', r"\\\\", sanitized)
             try:
-                return json.loads(repaired)
+                return dict(json.loads(repaired))
             except json.JSONDecodeError as e2:
                 logger.error(
                     "Failed to parse manifest for %s: %s. Using empty manifest.",
@@ -109,8 +180,34 @@ def extract_metadata_lightweight(manifest: dict[str, Any]) -> dict[str, Any]:
         Dict with keys: subject, from, to, cc, start_date, end_date
     """
     man = manifest or {}
-    subject = (man.get("smart_subject") or man.get("subject") or "").strip()
+    return {
+        "subject": _extract_subject_lightweight(man),
+        **_extract_participants_grouped(man),
+        **_extract_date_range(man),
+    }
+
+
+def _extract_subject_lightweight(manifest: dict[str, Any]) -> str:
+    raw = manifest.get("smart_subject")
+    if not isinstance(raw, str):
+        raw = manifest.get("subject")
+    if not isinstance(raw, str):
+        raw = ""
+    return raw.strip()
 
+
+def parse_manifest_core(man: dict[str, Any]) -> dict[str, Any]:
+    man = man or {}
+    return {
+        "subject": _extract_subject_lightweight(man),
+        **_extract_participants_grouped(man),
+        **_extract_date_range(man),
+    }
+
+
+def _extract_participants_grouped(
+    manifest: dict[str, Any],
+) -> dict[str, list[tuple[str, str]]]:
     from_list: list[tuple[str, str]] = []
     to_list: list[tuple[str, str]] = []
     cc_list: list[tuple[str, str]] = []
@@ -119,105 +216,130 @@ def extract_metadata_lightweight(manifest: dict[str, Any]) -> dict[str, Any]:
     seen_to: set[str] = set()
     seen_cc: set[str] = set()
 
-    def _add_pair(
-        out: list[tuple[str, str]], seen: set[str], name: str, email: str
-    ) -> None:
-        name_s = (name or "").strip()
-        email_s = (email or "").strip()
-        if not name_s and not email_s:
-            return
-        key = email_s.lower() if email_s else f"name:{_normalize_name(name_s)}"
-        if not key or key in seen:
-            return
-        seen.add(key)
-        out.append((name_s, email_s))
-
-    # Aggregate from/to/cc across all messages (deduplicated)
-    try:
-        msgs = man.get("messages") or []
-        if isinstance(msgs, list):
-            for msg in msgs:
-                if not isinstance(msg, dict):
-                    continue
-
-                f = msg.get("from")
-                if isinstance(f, dict):
-                    _add_pair(
-                        from_list, seen_from, f.get("name", ""), f.get("smtp", "")
-                    )
+    msgs = manifest.get("messages") or []
+    if not isinstance(msgs, list):
+        return {"from": [], "to": [], "cc": []}
 
-                for rec in msg.get("to") or []:
-                    if isinstance(rec, dict):
-                        _add_pair(
-                            to_list, seen_to, rec.get("name", ""), rec.get("smtp", "")
-                        )
-
-                for rec in msg.get("cc") or []:
-                    if isinstance(rec, dict):
-                        _add_pair(
-                            cc_list, seen_cc, rec.get("name", ""), rec.get("smtp", "")
-                        )
-    except Exception:
-        pass
+    for msg in msgs:
+        if not isinstance(msg, dict):
+            continue
+        _process_message_participants(
+            msg, from_list, to_list, cc_list, seen_from, seen_to, seen_cc
+        )
 
-    # Dates: best-effort min/max across messages (falls back to first/last)
+    return {"from": from_list, "to": to_list, "cc": cc_list}
+
+
+def _process_message_participants(
+    msg: dict[str, Any],
+    from_list: list[tuple[str, str]],
+    to_list: list[tuple[str, str]],
+    cc_list: list[tuple[str, str]],
+    seen_from: set[str],
+    seen_to: set[str],
+    seen_cc: set[str],
+) -> None:
+    f = msg.get("from")
+    if isinstance(f, dict):
+        _add_pair(from_list, seen_from, f.get("name", ""), f.get("smtp", ""))
+
+    for rec in msg.get("to") or []:
+        if isinstance(rec, dict):
+            _add_pair(to_list, seen_to, rec.get("name", ""), rec.get("smtp", ""))
+
+    for rec in msg.get("cc") or []:
+        if isinstance(rec, dict):
+            _add_pair(cc_list, seen_cc, rec.get("name", ""), rec.get("smtp", ""))
+
+
+def _add_pair(
+    out: list[tuple[str, str]], seen: set[str], name: str, email: str
+) -> None:
+    name_s = (name or "").strip()
+    email_s = (email or "").strip()
+    if not name_s and not email_s:
+        return
+    key = email_s.lower() if email_s else f"name:{_normalize_name(name_s)}"
+    if not key or key in seen:
+        return
+    seen.add(key)
+    out.append((name_s, email_s))
+
+
+def _extract_date_range(manifest: dict[str, Any]) -> dict[str, Any]:
     start_date = None
     end_date = None
     try:
-        msgs = man.get("messages") or []
+        msgs = manifest.get("messages") or []
         if isinstance(msgs, list) and msgs:
+            # Fallback to first/last if parsing fails or returns no valid dates
             raw_start = msgs[0].get("date") if isinstance(msgs[0], dict) else None
             raw_end = msgs[-1].get("date") if isinstance(msgs[-1], dict) else None
 
-            from datetime import datetime
-
-            def _parse_dt(v: Any) -> datetime | None:
-                if v is None:
-                    return None
-                if isinstance(v, (int, float)):
-                    try:
-                        return datetime.fromtimestamp(float(v), tz=UTC)
-                    except Exception:
-                        return None
-                if isinstance(v, str):
-                    s = v.strip()
-                    if not s:
-                        return None
-                    if s.endswith("Z"):
-                        s = s[:-1] + "+00:00"
-                    try:
-                        dt = datetime.fromisoformat(s)
-                        if dt.tzinfo is None:
-                            dt = dt.replace(tzinfo=UTC)
-                        return dt
-                    except Exception:
-                        return None
-                return None
-
-            dts: list[datetime] = []
-            for msg in msgs:
-                if isinstance(msg, dict) and msg.get("date") is not None:
-                    dt = _parse_dt(msg.get("date"))
-                    if dt is not None:
-                        dts.append(dt)
-
+            dts = _parse_all_dates(msgs)
             if dts:
-                start_date = min(dts).astimezone(UTC).isoformat()
-                end_date = max(dts).astimezone(UTC).isoformat()
+                start_date = min(dts).astimezone(timezone.utc).isoformat()
+                end_date = max(dts).astimezone(timezone.utc).isoformat()
             else:
                 start_date = raw_start
                 end_date = raw_end
     except Exception:
         pass
 
-    return {
-        "subject": subject,
-        "from": from_list,
-        "to": to_list,
-        "cc": cc_list,
-        "start_date": start_date,
-        "end_date": end_date,
-    }
+    return {"start_date": start_date, "end_date": end_date}
+
+
+def _parse_all_dates(msgs: list[Any]) -> list[Any]:
+    dts: list[datetime] = []
+    for msg in msgs:
+        if isinstance(msg, dict) and msg.get("date") is not None:
+            dt = _parse_dt(msg.get("date"))
+            if dt is not None:
+                dts.append(dt)
+    return dts
+
+
+def _parse_dt(v: Any) -> Any | None:
+    if v is None:
+        return None
+    if isinstance(v, (int, float)):
+        try:
+            return datetime.fromtimestamp(float(v), tz=timezone.utc)
+        except Exception:
+            return None
+    if isinstance(v, str):
+        s = v.strip()
+        if not s:
+            return None
+        if s.endswith("Z"):
+            s = s[:-1] + "+00:00"
+        try:
+            dt = datetime.fromisoformat(s)
+            if dt.tzinfo is None:
+                dt = dt.replace(tzinfo=timezone.utc)
+            return dt
+        except Exception:
+            return None
+    return None
+
+
+# ============================================================================
+# Subject Resolution (Canonical)
+# ============================================================================
+def resolve_subject(
+    manifest: dict[str, Any], summary: dict[str, Any] | None, folder_name: str
+) -> tuple[str, str]:
+    """Resolve display and normalized subject from manifest/summary/folder."""
+
+    subject_display = (
+        (manifest or {}).get("smart_subject")
+        or (manifest or {}).get("subject_label")
+        or (manifest or {}).get("subject")
+        or (summary or {}).get("subject")
+        or folder_name
+    )
+    subject_norm = normalize_subject(subject_display)
+    return subject_display, subject_norm
 
 
 # ============================================================================
@@ -232,26 +354,20 @@ def extract_participants_detailed(
 ) -> list[dict[str, str]]:
     """
     Extract detailed participant information from manifest for summarization.
-
+    THIS CONSOLIDATES logic from:
+    - feature_summarize._participants_from_manifest()
     Returns rich participant schema with:
-      - name: Participant name
-      - email: Email address
-      - role: One of [client, broker, underwriter, internal, other]
-      - tone: One of [professional, frustrated, urgent, friendly, demanding, neutral]
-      - stance: Their position/attitude in the thread
-
-    Notes:
-      - Aggregates participants across all messages (sender + recipients).
-      - Deduplicates by email (preferred) or normalized name.
-      - Applies defaults; downstream summarization can refine role/tone/stance.
-
+    - name: Participant name
+    - email: Email address
+    - role: One of [client, broker, underwriter, internal, other]
+    - tone: One of [professional, frustrated, urgent, friendly, demanding, neutral]
+    - stance: Their position/attitude in the thread
     Args:
         manifest: Parsed manifest dict
         default_role: Default role when unknown (default: "other")
         default_tone: Default tone when unknown (default: "neutral")
         default_stance: Default stance when unknown (default: "N/A")
         max_participants: Maximum number to return (default: 25)
-
     Returns:
         List of participant dicts with full schema, deduplicated
     """
@@ -264,6 +380,7 @@ def extract_participants_detailed(
         return []
 
     def _mk(name: str, email: str, role: str = "other") -> dict[str, str]:
+        """Helper to create participant dict with defaults."""
         return {
             "name": _safe_str(name, 80),
             "role": role,
@@ -278,6 +395,7 @@ def _mk(name: str, email: str, role: str = "other") -> dict[str, str]:
             logger.debug("extract_participants_detailed: No messages in manifest")
             return []
 
+        # Iterate over ALL messages to find participants
         for msg in messages:
             if not isinstance(msg, dict):
                 continue
@@ -294,6 +412,7 @@ def _mk(name: str, email: str, role: str = "other") -> dict[str, str]:
                         _mk(rec.get("name", ""), rec.get("smtp", ""), role=default_role)
                     )
 
+            # Cc
             for rec in msg.get("cc") or []:
                 if isinstance(rec, dict):
                     out.append(
@@ -304,26 +423,24 @@ def _mk(name: str, email: str, role: str = "other") -> dict[str, str]:
         logger.warning(
             "extract_participants_detailed: Error extracting participants: %s", e
         )
+        return []
     except Exception as e:
         logger.error("extract_participants_detailed: Unexpected error: %s", e)
-
+        return []
     # Deduplicate by lowercase email or normalized name; skip empty entries
     seen: set[str] = set()
     deduped: list[dict[str, str]] = []
-    for p_item in out:
-        email_key = (p_item.get("email") or "").lower()
-        name_key = _normalize_name(p_item.get("name", ""))
+    for p in out:
+        email_key = (p.get("email") or "").lower()
+        name_key = _normalize_name(p.get("name", ""))
         if not email_key and not name_key:
             continue
         key = email_key or f"name:{name_key}"
         if key in seen:
             continue
         seen.add(key)
-        deduped.append(p_item)
-        if len(deduped) >= max_participants:
-            break
-
-    return deduped
+        deduped.append(p)
+    return deduped[:max_participants]
 
 
 # ============================================================================
@@ -381,4 +498,6 @@ def get_conversation_metadata(convo_dir: Path) -> dict[str, Any]:
     "extract_participants_detailed",
     "get_conversation_metadata",
     "load_manifest",
-]
+    "parse_manifest_text",
+    "resolve_subject",
+)
